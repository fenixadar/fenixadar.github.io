{"meta":{"title":"FenixAdar Blog","subtitle":"liaoyuanyue blog","description":"","author":"FenixAdar","url":"https://fenixadar.github.io","root":"/"},"pages":[{"title":"about","date":"2022-08-04T10:46:42.844Z","updated":"2022-08-04T10:46:42.844Z","comments":false,"path":"about/index.html","permalink":"https://fenixadar.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"极简Prometheus监控实战","slug":"极简Prometheus监控实战","date":"2022-08-04T02:47:39.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2022/08/04/极简Prometheus监控实战/","link":"","permalink":"https://fenixadar.github.io/2022/08/04/%E6%9E%81%E7%AE%80Prometheus%E7%9B%91%E6%8E%A7%E5%AE%9E%E6%88%98/","excerpt":"","text":"前言与目录监控是当前云原生时代下可观测性中关键性的一环，较之前相比，云原生时代已经发生了诸多变化，诸如微服务，容器化等技术层出不穷，且云原生时代的演进速度，更新速度极快，相对应监控所产生的数据量大大增加，对实时性的要求也大大增加。为应对变化，Prometheus应运而生，其所可实现的功能，与云原生极好的契合度，集成第三方开源组件的便利性，无疑使其成为无疑是最为耀眼的明星之一。 本文着重在于介绍如何利用Prometheus搭建监控系统，涵盖探针，指标设定，可视化，告警设定，容器监控等。这是一篇入门级教程，暂不涵盖gateway，K8S集群等的相关内容。关于Prometheus的基本知识与概念，自行google之，本文重点描述实战过程。 目录： 部署Prometheus Server 部署监控探针 部署Grafana 部署AlertManager 部署PrometheusAlert 二、部署Prometheus Server本节主要介绍以docker的方式部署Prometheus Server，并预留映射相关配置项 2.1 配置环境 创建文件夹并授予权限12sudo mkdir -pv /data/docker/prometheus/&#123;data,alert_rules,job&#125;sudo chown -R myusername:myusername /data/docker/prometheus/ 其中, data文件夹用于存放prometheus产生的数据 alert_rules文件夹用于存放prometheus alert告警规则配置文件 job用于存放监控对象配置json文件 myusername可替换为实际的用户名 执行本条命令以避免出现 permission denied 错误 1sudo chown 65534:65534 -R /data/docker/prometheus/data 拷贝配置文件到指定的目录，注意下，需要关注该文件中涉及“$ip”的部分，后续配置，诸如添加AlertManager后，记得返回修改修改此处。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: # - targets: [&quot;$ip:9093&quot;] # - alertmanager:9093# Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot; - /etc/prometheus/alert_rules/*.rules# A scrape configuration containing exactly one endpoint to scrape:# Here it&#x27;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &#x27;prometheus&#x27; file_sd_configs: - files: - /etc/prometheus/job/prometheus.json refresh_interval: 1m # 重载配置文件 # Node 主机组 - job_name: &#x27;host&#x27; #basic_auth: # username: prometheus # password: prometheus file_sd_configs: - files: - /etc/prometheus/job/host.json refresh_interval: 1m # cadvisor 容器组 - job_name: &#x27;cadvisor&#x27; file_sd_configs: - files: - /etc/prometheus/job/cadvisor.json refresh_interval: 1m # mysql exporter 组 - job_name: &#x27;mysqld-exporter&#x27; file_sd_configs: - files: - /etc/prometheus/job/mysqld-exporter.json refresh_interval: 1m # blackbox ping 组 - job_name: &#x27;blackbox_ping&#x27; scrape_interval: 5s scrape_timeout: 2s metrics_path: /probe params: module: [ping] file_sd_configs: - files: - /etc/prometheus/job/blackbox/ping/*.json refresh_interval: 1m relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: $ip:9115 # blackbox http get 2xx 组 - job_name: &#x27;blackbox_http_2xx&#x27; scrape_interval: 5s metrics_path: /probe params: module: [http_2xx] file_sd_configs: - files: - /etc/prometheus/job/blackbox/http_2xx/*.json refresh_interval: 1m relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: $ip:9115 - job_name: &quot;blackbox_tcp&quot; metrics_path: /probe params: module: [tcp_connect] file_sd_configs: - files: - /etc/prometheus/job/blackbox/tcp/*.json refresh_interval: 1m relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: $ip:9115 - job_name: &#x27;blackbox_ssh_banner&#x27; metrics_path: /probe params: module: [ssh_banner] file_sd_configs: - files: - /etc/prometheus/job/blackbox/ssh_banner/*.json refresh_interval: 1m relabel_configs: # Ensure port is 22, pass as URL parameter - source_labels: [__address__] regex: (.*?)(:.*)? replacement: $&#123;1&#125;:22 target_label: __param_target # Make instance label the target - source_labels: [__param_target] target_label: instance # Actually talk to the blackbox exporter though - target_label: __address__ replacement: $ip:9115 - job_name: &quot;blackbox_dns&quot; metrics_path: /probe params: module: [dns_udp] file_sd_configs: - files: - /etc/prometheus/job/blackbox/dns/*.json refresh_interval: 1m relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: $ip:9115 2.2 启动服务端12345678910111213141516171819docker run -itd \\ -p 9090:9090 \\ -v /data/docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro \\ -v /data/docker/prometheus/alert_rules:/etc/prometheus/alert_rules \\ -v /data/docker/prometheus/job:/etc/prometheus/job \\ -v /data/docker/prometheus/data:/data/prometheus/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ --name prometheus \\ --restart=always \\ prom/prometheus:v2.28.1 \\ --config.file=/etc/prometheus/prometheus.yml \\ --storage.tsdb.path=/data/prometheus/ \\ --storage.tsdb.retention.time=30d \\ --web.read-timeout=5m \\ --web.max-connections=10 \\ --query.max-concurrency=20 \\ --query.timeout=2m \\ --web.enable-lifecycle 启动成功后，通过浏览器访问 http://$ip:9090 可看到界面。 如果系统打开了防火墙，你可能需要给以下几个端口开白名单，以centos7为例， 1234sudo firewall-cmd --zone=public --add-port=9090/tcp --permanentsudo firewall-cmd --zone=public --add-port=9100/tcp --permanentsudo firewall-cmd --zone=public --add-port=3000/tcp --permanentsudo firewall-cmd --reload 2.3 部署 Prometheus Server 参考文档https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 三、部署监控探针Prometheus与Zabbix不同，Prometheus主要采用主动拉取的模式，通过Exporter提供的接口读取监控数据。Exporter负责采集数据，可以把Exporter理解为探针，并通过http的方式提供接口供Server调用读取数据，读者可自行google本文未描述的各个exporter提供的返回结果内字段的含义。 3.1 部署node_exporternode_exporter用于监控主机的CPU，内存，磁盘，I/O等的信息。侧重点在于主机系统本身的数据采集。 下载 node exporter 并解压 登录需要被监控的主机，可从 此处 下载 node exporter 或者运行 curl -O https://github.com/prometheus/node_exporter/releases/download/v1.2.0/node_exporter-1.2.0.linux-amd64.tar.gz 下载完成后，运行以下命令解压二进制包 123tar xvfz node_exporter-1.2.0.linux-amd64.tar.gzsudo mkdir -p /data/node_exporter/sudo mv node_exporter-1.2.0.linux-amd64/* /data/node_exporter/ 创建prometheus用户 123sudo groupadd prometheussudo useradd -g prometheus -m -d /var/lib/prometheus -s /sbin/nologin prometheussudo chown prometheus.prometheus -R /data/node_exporter/ 创建Systemd服务 添加并编辑文件 1sudo nano /etc/systemd/system/node_exporter.service 写入以下内容 1234567891011[Unit]Description=node_exporterDocumentation=https://prometheus.io/After=network.target[Service]Type=simpleUser=prometheusExecStart=/data/node_exporter/node_exporterRestart=on-failure[Install]WantedBy=multi-user.target 使用systemctl 启动 node exporter启动并查看服务是否正常12sudo systemctl start node_exportersudo systemctl status node_exporter 应该返回类似以下的文本 123456● node_exporter.service - node_exporter Loaded: loaded (/etc/systemd/system/node_exporter.service; disabled; vendor preset: disabled) Active: active (running) since 三 2019-06-05 09:18:56 GMT; 3s ago Main PID: 11050 (node_exporter) CGroup: /system.slice/node_exporter.service └─11050 /usr/local/prometheus/node_exporter/node_exporter 设置开机启动: sudo systemctl enable node_exporter 开启防火墙白名单执行curl localhost:9100，如可以看到返回的网页，说明 node exporter 已经启动成功了。在同网段内其他机器执行curl http://$ip:9100/，应同样可以看到返回的页面。 如果看不到返回的页面，可以检查下是否为防火墙端口未开 12sudo firewall-cmd --zone=public --add-port=9100/tcp --permanentsudo firewall-cmd --reload 配置 Prometheus登录 Prometheus 服务端，编辑以下文件nano /data/docker/prometheus/job/host.json, 内容参考如下，ip地址自行更改实际的ip地址 12345678910111213141516[ &#123; &quot;targets&quot;: [ &quot;192.168.1.100:9100&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;node_exporter&quot;, &quot;hostname&quot;: &quot;server1&quot; &#125; &#125;, &#123; &quot;targets&quot;: [ &quot;192.168.1.101:9100&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;node_exporter&quot;, &quot;hostname&quot;: &quot;server2&quot; &#125; &#125;] 部署 node_exporter 可参考文档https://github.com/prometheus/node_exporterhttps://prometheus.io/docs/guides/node-exporter/https://www.jianshu.com/p/7bec152d1a1f 3.2 部署mysqld-exportermysqld-exporter 用于监控MySQL数据库的性能等数据。 登录mysql数据库所在主机，并通过docker方式启动1234567docker run -d \\ -p 9104:9104 \\ --link mysql \\ --name mysqld-exporter \\ --restart on-failure:5 \\ -e DATA_SOURCE_NAME=&quot;root:pwdpwdpwdpwdpwd@(mysql:3306)/&quot; \\ prom/mysqld-exporter:v0.13.0 启动后，访问http://127.0.0.1:9104/metrics，可看到监控信息，同时从Prometheus服务端访问也应要可访问的到。 部署 mysqld-exporter 可参考文档https://github.com/prometheus/mysqld_exporterhttps://registry.hub.docker.com/r/prom/mysqld-exporter/ 3.3 部署cadvisorcadvisor用于监控容器的状态。 登录docker所在主机并通过运行以下脚本启动cadvisor12345678910111213docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:ro \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=9101:8080 \\ --detach=true \\ --name=cadvisor \\ --restart on-failure:5 \\ --privileged \\ --device=/dev/kmsg \\ gcr.io/cadvisor/cadvisor:v0.38.6 你可能会找到两种 cadvisor，一种是 gcr.io/cadvisor/cadvisor, 另一种是 google/cadvisor, 建议使用 gcr.io/cadvisor/cadvisor 配置 Prometheus 服务端登录Prometheus 服务端所在主机，编辑 nano /data/docker/prometheus/job/cadvisor.json 文件, 内容参考如下： 12345678910111213141516[ &#123; &quot;targets&quot;: [ &quot;192.168.1.100:9101&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;cadvisor&quot;, &quot;hostname&quot;: &quot;server1&quot; &#125; &#125;, &#123; &quot;targets&quot;: [ &quot;192.168.1.101:9101&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;cadvisor&quot;, &quot;hostname&quot;: &quot;server2&quot; &#125; &#125;] 如果docker所在主机存在防火墙，记得添加防火墙白名单 12sudo firewall-cmd --zone=public --add-port=9101/tcp --permanentsudo firewall-cmd --reload 部署 cadvisor 可参考文档https://github.com/google/cadvisor 3.4 部署blackbox_exporterblackbox_exporter 是以黑盒方式进行监控的工具 创建配置文件登录 Prometheus 服务端主机，执行以下命令12sudo mkdir -p /data/docker/blackbox/confsudo chown -R myusername:myusername /data/docker/blackbox 并添加编辑该文件 1nano /data/docker/blackbox/conf/blackbox.yml yml文件范本如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980modules: ping: prober: icmp timeout: 5s icmp: preferred_ip_protocol: &quot;ip4&quot; http_2xx: prober: http timeout: 5s http: method: GET preferred_ip_protocol: &quot;ip4&quot; # defaults to &quot;ip4&quot; ip_protocol_fallback: false # no fallback to &quot;ip6&quot; http_post_2xx: prober: http timeout: 5s http: method: POST preferred_ip_protocol: &quot;ip4&quot; http_post_2xx_json: prober: http timeout: 30s http: preferred_ip_protocol: &quot;ip4&quot; method: POST headers: Content-Type: application/json body: &#x27;&#123;&quot;key1&quot;:&quot;&quot;vlaue1,&quot;params&quot;:&#123;&quot;param2&quot;:&quot;vlaue2&quot;&#125;&#125;&#x27; http_basic_auth: prober: http timeout: 60s http: method: POST headers: Host: &quot;login.example.com&quot; basic_auth: username: &quot;username&quot; password: &quot;mysecret&quot; tls_connect: prober: tcp timeout: 5s tcp: tls: true tcp_connect: prober: tcp timeout: 5s pop3s_banner: prober: tcp tcp: query_response: - expect: &quot;^+OK&quot; tls: true ssh_banner: prober: tcp tcp: query_response: - expect: &quot;^SSH-2.0-&quot; - send: SSH-2.0-blackbox-ssh-check irc_banner: prober: tcp tcp: query_response: - send: &quot;NICK prober&quot; - send: &quot;USER prober prober prober :prober&quot; - expect: &quot;PING :([^ ]+)&quot; send: &quot;PONG $&#123;1&#125;&quot; - expect: &quot;^:[^ ]+ 001&quot; dns_udp: prober: dns timeout: 10s dns: transport_protocol: udp preferred_ip_protocol: ip4 query_name: &quot;www.example.cn&quot; query_type: &quot;A&quot; 配置 Prometheus继续在 Prometheus 服务端主机，执行以下命令1234sudo mkdir -p /data/docker/prometheus/job/blackbox/sudo mkdir -pv /data/docker/prometheus/job/blackbox/&#123;dns,http_2xx,ping,ssh_banner,tcp&#125;sudo chown -R myusername:myusername /data/docker/prometheus/job/blackbox/ 以下依次在/data/docker/prometheus/job/blackbox/下的对应的文件夹中，创建json文件，并参考样本写入配置 在dns文件夹下，创建 dns.json，样本如下 123456789[ &#123; &quot;targets&quot;: [ &quot;192.168.1.1&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;blackbox_dns&quot;, &quot;app&quot;: &quot;my_dns&quot; &#125; &#125;] 在http_2xx文件夹下，创建 search-site.json，样本如下 123456789101112131415161718[ &#123; &quot;targets&quot;: [ &quot;https://www.google.cn/?HealthCheck&quot;], &quot;labels&quot;: &#123; &quot;app&quot;: &quot;google&quot;, &quot;subject&quot;: &quot;blackbox_http_2xx&quot;, &quot;hostname&quot;: &quot;server-01&quot; &#125; &#125;, &#123; &quot;targets&quot;: [ &quot;https://cn.bing.com/?HealthCheck&quot;], &quot;labels&quot;: &#123; &quot;app&quot;: &quot;bing&quot;, &quot;subject&quot;: &quot;blackbox_http_2xx&quot;, &quot;hostname&quot;: &quot;server-02&quot; &#125; &#125;] 在ping文件夹下，创建 search-site.json，样本如下 123456789101112131415161718[ &#123; &quot;targets&quot;: [ &quot;www.google.cn&quot;], &quot;labels&quot;: &#123; &quot;app&quot;: &quot;google&quot;, &quot;subject&quot;: &quot;blackbox_ping&quot;, &quot;hostname&quot;: &quot;server-01&quot; &#125; &#125;, &#123; &quot;targets&quot;: [ &quot;cn.bing.com&quot;], &quot;labels&quot;: &#123; &quot;app&quot;: &quot;bing&quot;, &quot;subject&quot;: &quot;blackbox_ping&quot;, &quot;hostname&quot;: &quot;server-02&quot; &#125; &#125;] 在ssh_banner文件夹下，创建 ssh-banner.json，样本如下 12345678910111213141516[ &#123; &quot;targets&quot;: [ &quot;192.168.1.100:22&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;blackbox_ssh_banner&quot;, &quot;hostname&quot;: &quot;server-01&quot; &#125; &#125;, &#123; &quot;targets&quot;: [ &quot;192.168.1.101:22&quot;], &quot;labels&quot;: &#123; &quot;subject&quot;: &quot;blackbox_ssh_banner&quot;, &quot;hostname&quot;: &quot;server-02&quot; &#125; &#125;] 在tcp文件夹下，创建 tcp.json，样本如下 12345678910[ &#123; &quot;targets&quot;: [ &quot;$ip:3306&quot;], &quot;labels&quot;: &#123; &quot;app&quot;: &quot;mysql.example.cn&quot;, &quot;subject&quot;: &quot;blackbox_tcp&quot;, &quot;hostname&quot;: &quot;mysql&quot; &#125; &#125;] 运行blackbox_exporter 在 Prometheus服务端所在的主机，运行以下命令，使用容器启动blackbox_exporter 1234567docker run -d \\ --restart on-failure:5 \\ -p 9115:9115 \\ -v /data/docker/blackbox/conf/blackbox.yml:/config/blackbox.yml:ro \\ --name blackbox_exporter \\ prom/blackbox-exporter:v0.19.0 \\ --config.file=/config/blackbox.yml 启动成功后，访问http://$ip:9090/targets，可看到至今为止，我们配置的所有探针所反馈回来的数据，其中，State应为UP状态。 部署 blackbox_exporter 可参考文档https://github.com/prometheus/blackbox_exporterhttps://yunlzheng.gitbook.io/prometheus-book/part-ii-prometheus-jin-jie/exporter/commonly-eporter-usage/install_blackbox_exporter 四、部署Grafana接下来，部署可视化工具Grafana，Grafana可快速集成Prometheus，并通过设定甚至是使用现成的模板，快速将采集结果转变为图形化的页面。 4.1 启动运行以下命令，做启动前的准备工作 12sudo mkdir -p /data/docker/grafanasudo chown 472:472 /data/docker/grafana -R 通过docker运行grafana 12345678docker run -d \\ -p 3000:3000 \\ --name=grafana \\ -v /data/docker/grafana:/var/lib/grafana \\ -v /etc/localtime:/etc/localtime:ro \\ --restart=always \\ --name grafana \\ grafana/grafana:8.0.6 启动成功后，可通过http://$ip:3000访问页面，默认账号密码: admin / admin 。 4.2 配置 配置数据源点击“Configuration -&gt; Data sources”，进入 http://$ip:3000/datasources，增加Prometheus数据源，并做好配置。 配置Dashboards 点击“Dashboards -&gt; Manage -&gt; import”，进入http://$ip:3000/dashboard/import，导入 Grafana Dashboards 模板，在Import via grafana.com处，填入你想要导入的模板id，常用的模板id如下： node exporter ID: 8919 Cadvisor ID: 14282 mysqld-exporter ID: 7362 你也可以在https://grafana.com/grafana/dashboards，自行搜索 Dashboards 模板。也可以自行创建dashboard面板。 4.3 部署 Grafana 可参考文档https://grafana.com/docs/grafana/latest/installation/docker/ 五、部署AlertManager截至到现在，我们已经部署好Prometheus Server，Exporter，Grafana可视化组件，我们还需要配置告警组件，当故障出现时，监控系统可通过多种方式告知接收人，以便接收人及时知晓并处理。但Prometheus本身并不自带告警工具，Prometheus可以通过预配置的规则，将信息发送到AlertManager，由AlertManager统一处理告警信息，并通过邮箱，短信，微信，钉钉等方式告知告警接收人。和Grafana一样，AlertManager同样不仅仅支持Prometheus，也支持集成处理其他程序的信息。 5.1 准备工作运行以下命令 123sudo mkdir -pv /data/docker/alertmanagersudo chown -R myusername:myusername /data/docker/alertmanager/cd /data/docker/alertmanager 在/data/docker/alertmanager文件夹中，创建alertmanager.yml 和 email.tmpl 文件， alertmanager.yml的样例如下，注意要设置smtp相关配置项与webhook的ddurl： 1234567891011121314151617181920212223242526272829303132333435363738global: resolve_timeout: 5m # 邮件SMTP配置 smtp_smarthost: &#x27;smtp.gmail.com:465&#x27; smtp_from: &#x27;example@gmail.com&#x27; smtp_auth_username: &#x27;example@gmail.com&#x27; smtp_auth_password: &#x27;xxxxx&#x27; smtp_require_tls: false# 自定义通知模板templates: - &#x27;/etc/alertmanager/email.tmpl&#x27;# route用来设置报警的分发策略route: # 采用哪个标签来作为分组依据 group_by: [&#x27;alertname&#x27;] # 组告警等待时间。也就是告警产生后等待10s，如果有同组告警一起发出 group_wait: 10s # 两组告警的间隔时间 group_interval: 10s # 重复告警的间隔时间，减少相同邮件的发送频率 repeat_interval: 1h # 设置默认接收人 receiver: &#x27;myreceiver&#x27; routes: # 可以指定哪些组接手哪些消息 - receiver: &#x27;myreceiver&#x27; continue: true group_wait: 10sreceivers:- name: &#x27;myreceiver&#x27;#send_resolved: true email_configs: # - to: &#x27;example@gmail.com, example2@gmail.com&#x27; - to: &#x27;example@gmail.com&#x27; html: &#x27;&#123;&#123; template &quot;email.to.html&quot; . &#125;&#125;&#x27; headers: &#123; Subject: &quot;Prometheus [Warning] 报警邮件&quot; &#125; # 钉钉配置 webhook_configs: - url: &#x27;http://$ip:18080/prometheusalert?type=dd&amp;tpl=prometheus-dd&amp;ddurl=https://oapi.dingtalk.com/robot/send?access_token=xxxxxx&#x27; email.tmpl的样例如下，注意样例中有一个”2006-01-02 15:04:05”，这个时间不能改，否则报警显示时间可能会不正确： 12345678910111213141516171819202122232425262728293031&#123;&#123; define &quot;email.to.html&quot; &#125;&#125;&#123;&#123;- if gt (len .Alerts.Firing) 0 -&#125;&#125;&#123;&#123; range .Alerts &#125;&#125;=========start==========&lt;br&gt;告警程序: prometheus_alert &lt;br&gt;告警级别: &#123;&#123; .Labels.severity &#125;&#125; &lt;br&gt;告警类型: &#123;&#123; .Labels.alertname &#125;&#125; &lt;br&gt;告警应用: &#123;&#123; .Labels.app &#125;&#125; &lt;br&gt;告警主机: &#123;&#123; .Labels.instance &#125;&#125; &lt;br&gt;告警主题: &#123;&#123; .Annotations.summary &#125;&#125; &lt;br&gt;告警详情: &#123;&#123; .Annotations.description &#125;&#125; &lt;br&gt;触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125; &lt;br&gt;=========end==========&lt;br&gt;&#123;&#123; end &#125;&#125;&#123;&#123; end -&#125;&#125;&#123;&#123;- if gt (len .Alerts.Resolved) 0 -&#125;&#125;&#123;&#123; range .Alerts &#125;&#125;=========start==========&lt;br&gt;告警程序: prometheus_alert &lt;br&gt;告警级别: &#123;&#123; .Labels.severity &#125;&#125; &lt;br&gt;告警类型: &#123;&#123; .Labels.alertname &#125;&#125; &lt;br&gt;告警应用: &#123;&#123; .Labels.app &#125;&#125; &lt;br&gt;告警主机: &#123;&#123; .Labels.instance &#125;&#125; &lt;br&gt;告警主题: &#123;&#123; .Annotations.summary &#125;&#125; &lt;br&gt;告警详情: &#123;&#123; .Annotations.description &#125;&#125; &lt;br&gt;触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125; &lt;br&gt;恢复时间: &#123;&#123; (.EndsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125; &lt;br&gt;=========end==========&lt;br&gt;&#123;&#123; end &#125;&#125;&#123;&#123; end -&#125;&#125;&#123;&#123;- end &#125;&#125; 这两个配置文件，可参考 https://prometheus.io/docs/alerting/latest/configuration/ 进行修改。 5.1 启动AlertManager运行以下命令 123456docker run -d -p 9093:9093 \\ -v /data/docker/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro \\ -v /data/docker/alertmanager/email.tmpl/:/etc/alertmanager/email.tmpl:ro \\ --name alertmanager \\ --restart=always \\ prom/alertmanager:v0.22.2 5.3 访问启动成功后，可通过http://$ip:9093访问alertmanager组件 六、部署PrometheusAlert上节已经提到，Prometheus告警需由两部分组成，上节我们已经部署好AlertManager用于信息处理与通知，本节我们需要定义好Prometheus的配置规则，如此Prometheus便可以产生告警信息并发送到AlertManager。 6.1 准备工作运行以下命令 123sudo mkdir -p /data/docker/prometheus-alert/confsudo chown -R fenixadar:fenixadar /data/docker/prometheus-alert/nano /data/docker/prometheus-alert/conf/app.conf 从 https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/conf/app-example.conf 下载文件并移动到 /data/docker/prometheus-alert/conf/app.conf 6.2 启动运行以下命令开启prometheus-alert 123456docker run -d --publish=18080:8080 \\ -v /data/docker/prometheus-alert/conf/:/app/conf:ro \\ -v /data/docker/prometheus-alert/db/:/app/db \\ -v /data/docker/prometheus-alert/log/:/app/logs \\ --name prometheusalert-center \\ feiyu563/prometheus-alert:v-4.5.0 开启成功后，通过http://$ip:18080，访问prometheus-alert界面。用户密码已在 app.conf 中设置。 如果系统开启了防火墙，记得开放白名单 12sudo firewall-cmd --zone=public --add-port=18080/tcp --permanentsudo firewall-cmd --reload 6.3 配置 配置告警模板 点击AlertTemplate，进入http://$ip:18080/template，此处有各类可对接的第三方系统的模板。以钉钉的告警模板为例，将模版内容改为如下，主要是修正时间显示慢8小时的问题，以及增加一些信息 1234567891011121314151617181920212223242526&#123;&#123; $var := .externalURL&#125;&#125;&#123;&#123; range $k,$v:=.alerts &#125;&#125;&#123;&#123;if eq $v.status &quot;resolved&quot;&#125;&#125;## [Prometheus恢复信息](&#123;&#123;$v.generatorURL&#125;&#125;)#### [&#123;&#123;$v.labels.alertname&#125;&#125;](&#123;&#123;$var&#125;&#125;)###### 告警级别：&#123;&#123;$v.labels.level&#125;&#125;###### 开始时间：&#123;&#123;GetCSTtime $v.startsAt&#125;&#125;###### 结束时间：&#123;&#123;GetCSTtime $v.endsAt&#125;&#125;###### 故障主机名：&#123;&#123;$v.labels.hostname&#125;&#125;###### 故障主机IP：&#123;&#123;$v.labels.instance&#125;&#125;###### 故障应用：&#123;&#123;$v.labels.app&#125;&#125;###### 故障主机对象：&#123;&#123;$v.labels.subject&#125;&#125;##### &#123;&#123;$v.annotations.description&#125;&#125;![Prometheus](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)&#123;&#123;else&#125;&#125;## [Prometheus告警信息](&#123;&#123;$v.generatorURL&#125;&#125;)#### [&#123;&#123;$v.labels.alertname&#125;&#125;](&#123;&#123;$var&#125;&#125;)###### 告警级别：&#123;&#123;$v.labels.level&#125;&#125;###### 开始时间：&#123;&#123;GetCSTtime $v.startsAt&#125;&#125;###### 故障主机名：&#123;&#123;$v.labels.hostname&#125;&#125;###### 故障主机IP：&#123;&#123;$v.labels.instance&#125;&#125;###### 故障应用：&#123;&#123;$v.labels.app&#125;&#125;###### 故障主机对象：&#123;&#123;$v.labels.subject&#125;&#125;##### &#123;&#123;$v.annotations.description&#125;&#125;![Prometheus](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)&#123;&#123;end&#125;&#125;&#123;&#123; end &#125;&#125; 设置钉钉机器人在钉钉中，新建一个钉钉群，点击“群设置 -&gt; 智能群助手 -&gt; 添加机器人 -&gt; 自定义 -&gt; 安全设置”，把发送信息的服务器IP地址加进去，而后就会有 Webhook 地址。可参考 https://blog.csdn.net/knight_zhou/article/details/105583741 6.4 部署 PrometheusAlert 可参考文档https://github.com/feiyu563/PrometheusAlert/blob/master/doc/readme/install.md","categories":[],"tags":[]},{"title":"goframe与gin对比(四) 数据返回、Cookie、session、HTTPClient","slug":"goframe与gin对比(四) 数据返回、Cookie、session、HTTPClient","date":"2021-10-28T10:51:05.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/28/goframe与gin对比(四) 数据返回、Cookie、session、HTTPClient/","link":"","permalink":"https://fenixadar.github.io/2021/10/28/goframe%E4%B8%8Egin%E5%AF%B9%E6%AF%94(%E5%9B%9B)%20%E6%95%B0%E6%8D%AE%E8%BF%94%E5%9B%9E%E3%80%81Cookie%E3%80%81session%E3%80%81HTTPClient/","excerpt":"","text":"数据返回JSON/XML支持两者均支持序列化对象，输出json和xml格式数据 重定向两者均支持重定向，goframe还支持通过RedirectBack返回到上一个页面 goframe Redirect 中断控制goframe提供Exit，ExitAll,ExitHook用于中断当前执行的逻辑方法，其底层使用的是 panic，recover 机制实现。gin目前没有原生提供该功能。 goframe Exit控制 文件下载goframe 提供 ServeFileDownload 方法用于文件流式下载 gin需自行实现 goframe 文件下载 Cookie goframe 中的cookie是一个对象，对象还封装了 sessionId相关的方法 gin 的 cookie 比较简单，只是一个字符串 session goframe 通过request 获取 session，gin则是通过在中间件处引入gin-contrib/sessions库来实现 都支持把session放在cookie、redis、memcached、MongoDB等中。 HTTPClientgoframe 自带，gin则是由 net/http 提供","categories":[],"tags":[]},{"title":"goframe与gin对比(三) 请求输入","slug":"goframe与gin对比(三) 请求输入","date":"2021-10-28T10:50:36.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/28/goframe与gin对比(三) 请求输入/","link":"","permalink":"https://fenixadar.github.io/2021/10/28/goframe%E4%B8%8Egin%E5%AF%B9%E6%AF%94(%E4%B8%89)%20%E8%AF%B7%E6%B1%82%E8%BE%93%E5%85%A5/","excerpt":"","text":"请求输入复杂参数同名参数同名参数提交格式形如：k=v1&amp;k=v2, goframe是后续的变量值将会覆盖前面的变量值，而gin因为用的标准库net/http, 提交的同名参数将会被转换为字符串数组。 123456789101112131415package mainimport ( &quot;github.com/gogf/gf/frame/g&quot; &quot;github.com/gogf/gf/net/ghttp&quot;)func main() &#123; s := g.Server() s.BindHandler(&quot;/&quot;, func(r *ghttp.Request) &#123; r.Response.Write(r.Get(&quot;name&quot;)) &#125;) s.SetPort(8199) s.Run()&#125; 访问http://localhost:8199/?name=john&amp;name=smith, 得到smith 12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; name := c.Query(&quot;name&quot;) nameArray := c.QueryArray(&quot;name&quot;) c.String(http.StatusOK, fmt.Sprintf(&quot;hello %s &quot;, name)) c.String(http.StatusOK, fmt.Sprintf(&quot;hello %s %s&quot;, nameArray[0], nameArray[1])) &#125;) r.Run()&#125; 访问http://localhost:8080/?array=john&amp;array=smith, 得到hello john hello john smith 数组参数数组参数提交格式形如：k[]=v1&amp;k[]=v2, goframe 与 gin 相同 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; // http://localhost:8080/?array[]=john&amp;array[]=smith array := c.QueryArray(&quot;array[]&quot;) c.String(http.StatusOK, fmt.Sprintf(&quot;hello %s %s&quot;, array[0], array[1])) &#125;) r.Run()&#125; 访问http://localhost?array[]=john&amp;array[]=smith, 得到[&quot;john&quot;,&quot;smith&quot;] 1234567891011121314package mainimport ( &quot;github.com/gogf/gf/frame/g&quot; &quot;github.com/gogf/gf/net/ghttp&quot;)func main() &#123; s := g.Server() s.BindHandler(&quot;/&quot;, func(r *ghttp.Request) &#123; r.Response.Write(r.Get(&quot;array&quot;)) &#125;) s.Run()&#125; 访问http://localhost:8080/?array[]=john&amp;array[]=smith, 得到hello john smith 对象处理可将数据解析与绑定分为 json, xml, 表单, uri 等几种。goframe和gin均支持这几种数据的绑定与解析。 goframe推荐使用 parse转换来实现struct的转换。可参考goframe请求输入-对象处理文档 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;github.com/gogf/gf/frame/g&quot; &quot;github.com/gogf/gf/net/ghttp&quot;)type RegisterReq struct &#123; Name string Pass string `p:&quot;password1&quot;` Pass2 string `p:&quot;password2&quot;`&#125;type RegisterRes struct &#123; Code int `json:&quot;code&quot;` Error string `json:&quot;error&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125;func main() &#123; s := g.Server() s.BindHandler(&quot;/register&quot;, func(r *ghttp.Request) &#123; var req *RegisterReq if err := r.Parse(&amp;req); err != nil &#123; r.Response.WriteJsonExit(RegisterRes&#123; Code: 1, Error: err.Error(), &#125;) &#125; // ... r.Response.WriteJsonExit(RegisterRes&#123; Data: req, &#125;) &#125;) s.SetPort(8199) s.Run()&#125; 访问http://127.0.0.1:8199/register?name=john&amp;password1=123&amp;password2=456, 得到&#123;&quot;code&quot;:0,&quot;error&quot;:&quot;&quot;,&quot;data&quot;:&#123;&quot;Name&quot;:&quot;john&quot;,&quot;Pass&quot;:&quot;123&quot;,&quot;Pass2&quot;:&quot;456&quot;&#125;&#125; gin 和 goframe 类似 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)type RegisterReq struct &#123; Name string Pass string `form:&quot;password1&quot; binding:&quot;required&quot;` Pass2 string `form:&quot;password2&quot; binding:&quot;required&quot;`&#125;type RegisterRes struct &#123; Code int `json:&quot;code&quot;` Error string `json:&quot;error&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125;func main() &#123; r := gin.Default() r.GET(&quot;/register&quot;, func(c *gin.Context) &#123; var req RegisterReq if err := c.ShouldBind(&amp;req); err != nil &#123; c.JSON(http.StatusBadRequest, RegisterRes&#123; Code: 1, Error: err.Error(), Data: req&#125;) return &#125; c.JSON(http.StatusOK, RegisterRes&#123;Data: req&#125;) &#125;) r.Run()&#125; 访问http://localhost:8080/register?name=john&amp;password1=pwd1&amp;password2=pwd2，可得到&#123;&quot;code&quot;:0,&quot;error&quot;:&quot;&quot;,&quot;data&quot;:&#123;&quot;Name&quot;:&quot;&quot;,&quot;Pass&quot;:&quot;pwd1&quot;,&quot;Pass2&quot;:&quot;pwd2&quot;&#125;&#125; 展示的案例是绑定get请求的query参数，其他的情况可参考 只绑定Get参数 官方只绑定Get参数 中文绑定Get参数或者Post参数 官方绑定Get参数或者Post参数 中文绑定uri 官方绑定uri 中文绑定HTML复选框 官方绑定HTML复选框 中文绑定Post参数 官方绑定Post参数 中文表单数据解析和绑定URI数据解析和绑定 JSON/XML从GoFrame v1.11版本开始，Request对象提供了对客户端提交的JSON/XML数据格式的原生支持。可通过 Parse 方法转换json或xml 具体案例可参考 GoFrame 请求输入JSON/XML转换 gin也类似，gin提供 Must bind 和 Should bind 两种绑定方法，具体使用时根据 json，xml，yaml等使用不同的函数。两种绑定方法的区别在于当存在绑定错误时是否直接终止请求亦或者交由开发人员处理。 具体案例可参考模型绑定和验证 官方模型绑定和验证 中文Json 数据解析和绑定 请求校验goframe 和 gin 的校验方式形式上差不多，都支持自定义的校验模式，不同的是，goframe还支持将错误转换为错误接口，这样可以控制不一次性输出全部错误，一次性输出全部错误有时候对用户并不友好。诸如每次只输出第一个校验错误。 goframe 请求校验示例gin 自定义校验示例gin 结构体验证gin 自定义验证 默认值绑定goframe 和 gin 都支持默认值绑定，uri，query,form等都是支持默认值的。默认值绑定的一个常用场景是，列表分页时的每页默认条数和当前页数的赋值。 goframe 默认值绑定 示例 goframe支持json的默认值绑定，而gin并不能直接在结构体定义的时候设置默认值，可行的方法在实例化json时再自行设置默认值。gin官方文档中并没详细如何处理参数的默认值问题，所以我下面写个示例补充一下。 gin的uri，form等默认取值比较简单，使用 DefaultQuery 和 DefaultPostForm 即可解决默认值的问题 123route.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.DefaultQuery(&quot;name&quot;, &quot;john&quot;)&#125;) 或者，也可以在定义结构体的时候声明 1234type ListInfo struct &#123; Page int `form:&quot;page,default=1&quot; json:&quot;page&quot; xml:&quot;page&quot; ` Size int `form:&quot;size,default=10&quot; json:&quot;size&quot; xml:&quot;size&quot; `&#125; gin设定 json 与 xml 的默认值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)// Binding from JSONtype ListInfo struct &#123; Page int `form:&quot;page,default=1&quot; json:&quot;page&quot; xml:&quot;page&quot; ` Size int `form:&quot;size,default=10&quot; json:&quot;size&quot; xml:&quot;size&quot; `&#125;func main() &#123; router := gin.Default() // Example for binding JSON (&#123;&quot;user&quot;: &quot;manu&quot;, &quot;password&quot;: &quot;123&quot;&#125;) router.POST(&quot;/listJSON&quot;, func(c *gin.Context) &#123; json := ListInfo&#123; Page: 1, Size: 10, &#125; if err := c.ShouldBindJSON(&amp;json); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;error&quot;: err.Error()&#125;) return &#125; c.JSON(http.StatusOK, json) &#125;) // Example for binding XML ( // &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; // &lt;root&gt; // &lt;page&gt;1&lt;/page&gt; // &lt;size&gt;10&lt;/size&gt; // &lt;/root&gt;) router.POST(&quot;/listXML&quot;, func(c *gin.Context) &#123; xml := ListInfo&#123; Page: 1, Size: 10, &#125; if err := c.ShouldBindXML(&amp;xml); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;error&quot;: err.Error()&#125;) return &#125; c.JSON(http.StatusOK, xml) &#125;) // Listen and serve on 0.0.0.0:8080 router.Run(&quot;:8080&quot;)&#125; 自定义变量 与 Context开发者可以在请求中自定义一些变量设置, goframe 和 gin 都支持。 goframe文档 自定义变量goframe文档 Contextgin中间件","categories":[],"tags":[]},{"title":"goframe与gin对比(二) 路由管理","slug":"goframe与gin对比(二) 路由管理","date":"2021-10-28T10:49:58.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/28/goframe与gin对比(二) 路由管理/","link":"","permalink":"https://fenixadar.github.io/2021/10/28/goframe%E4%B8%8Egin%E5%AF%B9%E6%AF%94(%E4%BA%8C)%20%E8%B7%AF%E7%94%B1%E7%AE%A1%E7%90%86/","excerpt":"","text":"路由管理路由规则goframe 的动态路由的底层数据结构是由层级哈希表和双向链表构建的路由树。gin 路由算法是前缀树(Trie), 时间复杂度是 O(n)。 可参考 gin的路由算法 当gin出现路由规则重复时，会报错。而goframe则是按照深度优先策略进行优先级控制。主要规则如下： 层级越深的规则优先级越高； 同一层级下，精准匹配优先级高于模糊匹配； 同一层级下，模糊匹配优先级：字段匹配 &gt; 命名匹配 &gt; 模糊匹配 gin和goframe都支持命名匹配规则、模糊匹配规则，不建议使用模糊匹配规则，容易引起冲突。 gin 不支持 goframe中的字段匹配规则，但实际上也可以做到类似效果 路由匹配参考文档 goframe路由管理-路由规则 gin路由规则 本节gin示例代码： 12345678910111213141516171819202122232425262728package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/:name&quot;, func(c *gin.Context) &#123; c.String(200, c.FullPath()) &#125;) r.GET(&quot;/:name/update&quot;, func(c *gin.Context) &#123; c.String(200, c.FullPath()) &#125;) r.GET(&quot;/:name/:action&quot;, func(c *gin.Context) &#123; c.String(200, c.FullPath()) &#125;) r.GET(&quot;/:name/*any&quot;, func(c *gin.Context) &#123; c.String(200, c.FullPath()) &#125;) //因与上面规则产生冲突，go run 时报错 // r.GET(&quot;/:name/list/&#123;field&#125;.html&quot;, func(c *gin.Context) &#123; // c.String(200, c.FullPath()) // &#125;) //暂不支持该匹配模式，可采用下面这种模式代替 r.GET(&quot;/:name/hello-:action&quot;, func(c *gin.Context) &#123; c.String(200, c.FullPath()) &#125;) r.Run()&#125; 本节goframe示例代码： 123456789101112131415161718192021222324252627package mainimport ( &quot;github.com/gogf/gf/frame/g&quot; &quot;github.com/gogf/gf/net/ghttp&quot;)func main() &#123; s := g.Server() s.BindHandler(&quot;/:name&quot;, func(r *ghttp.Request) &#123; r.Response.Writeln(r.Router.Uri) &#125;) s.BindHandler(&quot;/:name/update&quot;, func(r *ghttp.Request) &#123; r.Response.Writeln(r.Router.Uri) &#125;) s.BindHandler(&quot;/:name/:action&quot;, func(r *ghttp.Request) &#123; r.Response.Writeln(r.Router.Uri) &#125;) s.BindHandler(&quot;/:name/*any&quot;, func(r *ghttp.Request) &#123; r.Response.Writeln(r.Router.Uri) &#125;) s.BindHandler(&quot;/user/list/&#123;field&#125;.html&quot;, func(r *ghttp.Request) &#123; r.Response.Writeln(r.Router.Uri) &#125;) s.SetPort(8199) s.Run()&#125; 路由注册goframe 路由注册有函数注册和对象注册两种，并支持分组路由 可参考 goframe路由注册文档 gin 在小型项目情况下，可简单使用类似函数注册的方法，当项目规模变大后，可以对路由进行拆分，形成单独的文件或者包。这时，可以在单独的文件中，完成路由注册工作。当项目继续膨胀，可以通过定义多个路由文件来注册路由。 如果项目规模实在太大，可以根据业务线拆分路由，将代码拆分到多个文件中，并利用Include函数注册子模块中定义的路由，利用Init函数初始化路由。 可参考 gin路由拆分与注册 goframe 和 gin 都支持路由分组功能 路由分组可以更加高效的管理一系列URL，诸如统一前缀，鉴权校验，错误处理等，建议使用。 goframe 和 gin 都可以通过在路由组中添加中间件，来添加诸如鉴权，日志记录等特性。goframe还可以通过HOOK的方式注册路由。 [goframe分组路由文档]（https://goframe.org/pages/viewpage.action?pageId=1114479）goframe HOOK事件回调gin路由分组 中间件原理类似aop，亦或者，虽然gin将其描述为middleware，但个人认为称呼为拦截器更加合适。 goframe和gin都有全局中间件和局部中间件的概念，能实现的功能类似。 下面goframe中间件的文档中，有5个中间件示例，分别是，允许跨域请求、请求鉴权处理、鉴权例外处理、统一的错误处理、自定义日志处理，均是常用中间件的范例，值得一看。 goframe中间件文档goframe中间件设计gin中间件文档","categories":[],"tags":[]},{"title":"goframe与gin对比(一) 综述","slug":"goframe与gin对比(一) 综述","date":"2021-10-28T10:49:15.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/28/goframe与gin对比(一) 综述/","link":"","permalink":"https://fenixadar.github.io/2021/10/28/goframe%E4%B8%8Egin%E5%AF%B9%E6%AF%94(%E4%B8%80)%20%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"综述整体优缺点可以把goframe比作 windows，整体性强，结合都高，开箱即用。而gin，则类似于linux，各组件小而独立，通过融合各个组件，完全可以组成一个比goframe更好的二开平台，但技术要求高，时间跨度长。 goframe 优点 整体全面，基本覆盖建设企业级系统所需的组件 文档全面具体，基本上可以在文档中找到答案。 goframe 缺点 有停止维护的风险 较封闭，类似微软DotNet，平台涉及各个方面，一旦出现bug，无法整体替换，第三方组件兼容性尚不明确 虽然官方文档全面，但公网上文档比较少 gin 优点 较轻量级，事实上是加了路由和模板功能的net/http库 第三方组件兼容性好，可以自由选择第三方组件 gin 缺点 过于轻量级，初学者初期需要花时间去寻找学习第三方组件的使用方式，并将其融合到项目中 官方文档较简单 没有工程化的组件，需要自行研究引入。 核心关注点开发文档 goframe 全面具体。 gin 官方文档过于简单，有基础的示例，但不全。具体问题需要大量求助于google ORM goframe 使用自带的 gdb 实现 gin 可通过引入第三方(如gorm)实现 路由管理路由规则和注册方法有一些区别，goframe 路由存在优先级，会按照优先级排序，gin 则是出现冲突时直接报错。中间件方面能实现的功能类似。 请求输入 对待输入参数的顺序处理有一些区别。主要是因为底层依赖的库不一样，但最终能达到的结果差不多。 转换 对象，json，xml 为结构体相差不多，gin不支持 json，xml 参数绑定默认值，但影响不大，可用其他方法实现赋予默认值。 都支持ctx中自定义变量 cookie goframe 中的cookie是一个对象，对象还封装了 sessionId相关的方法 gin 的 cookie 比较简单，只是一个字符串 session goframe 通过request 获取 session，gin则是通过在中间件处引入gin-contrib/sessions库来实现 都支持把session放在cookie、redis、memcached、MongoDB等中。 配置管理 goframe自带 gin 无 日志组件 goframe 功能较为全面，涵盖日志级别，错误堆栈打印，链式操作等特性。 gin 使用中间件，可以将日志输出，只能完成基本功能，这种做法可能会有性能瓶颈，需引入第三方，增强功能，提高性能。 错误处理 goframe 可输出错误堆栈，添加错误码，以对开发者友好的方式输出 gin则是以go原生异常抛出方式处理。 数据校验 goframe 自带 gin 默认引入第三方解决 类型转换 goframe 自带，支持基本类型，map，结构体。高级用法支持通过scan方法实现任意参数到struct/struct数组/map/map数组的转换，并且根据开发者输入的转换目标参数自动识别执行转换。支持通过自定义类型转换规则做类型转换。 gin 无 缓存管理 goframe 自带，支持内存缓存，redis适配，通过缓存适配实现存储到对应的cache对象上。 gin 无 模板引擎不使用，未对比 链路跟踪 goframe 自带OpenTelemetry实施标准支持 gin 无 微服务支持 除链路跟踪外，无区别。 当前都尚未考虑到大规模微服务场景支持。 实用工具类 goframe自带，较全 gin 无 构建部署流程无区别","categories":[],"tags":[]},{"title":"使用触发器记录表内数据变更日志","slug":"使用触发器记录表内数据变更日志","date":"2021-10-26T06:28:53.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/26/使用触发器记录表内数据变更日志/","link":"","permalink":"https://fenixadar.github.io/2021/10/26/%E4%BD%BF%E7%94%A8%E8%A7%A6%E5%8F%91%E5%99%A8%E8%AE%B0%E5%BD%95%E8%A1%A8%E5%86%85%E6%95%B0%E6%8D%AE%E5%8F%98%E6%9B%B4%E6%97%A5%E5%BF%97/","excerpt":"","text":"一、遇到的问题因为系统升级改造，遇到的问题是，新老两个数据库的两张表需要做数据同步，这两张表的表结构不完全相同，同步时会用类似nifi这种etl工具做转换。由于是线上系统，不可随意对原有的表结构进行变更。由于是老旧系统，业务繁杂，短时间内无法理清代码逻辑，也就不能从代码层做处理。 用nifi做数据同步时，发现特别是数据删除这种场景，会需要全表扫描做对比，得到被删掉的项，而后在另外一张表中做删除动作，这种方法性能极差。 于是，想到在数据库层面利用触发器记录变化的数据的id，同步时针对id进行同步，可大大提高性能。 二、触发器文档基本语法CREATE [DEFINER = user] TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW [trigger_order] trigger_bodytrigger_time: { BEFORE | AFTER }trigger_event: { INSERT | UPDATE | DELETE }trigger_order: { FOLLOWS | PRECEDES } other_trigger_name 触发时间有BEFORE和AFTER两种触发事件，涵盖 增改删 三类，drop table，truncate table 不会激活触发器 参考文档mysql官方文档 触发器语法和示例mysql官方文档 创建触发器 mysql非官方中文文档 触发器语法和示例mysql非官方中文文档 创建触发器 注意点 Cascaded foreign key actions do not activate triggers. Within the trigger body, the OLD and NEW keywords enable you to access columns in the rows affected by a trigger. OLD and NEW are MySQL extensions to triggers; they are not case-sensitive.In a DELETE trigger, only OLD.col_name can be used; there is no new row.In an UPDATE trigger, you can use OLD.col_name to refer to the columns of a row before it is updated and NEW.col_name to refer to the columns of the row after it is updated.In an INSERT trigger, only NEW.col_name can be used; there is no old row. 触发器执行失败导致的事务回滚 三、准备测试版本 mysql 5.6.51 12345678910111213141516171819DROP TABLE IF EXISTS `t_user`;CREATE TABLE `t_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(128) CHARACTER SET latin1 COLLATE latin1_swedish_ci NOT NULL COMMENT &#x27;名称&#x27;, `remark` varchar(512) CHARACTER SET latin1 COLLATE latin1_swedish_ci NOT NULL COMMENT &#x27;备注&#x27;, `created_at` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP(0) COMMENT &#x27;创建时间&#x27;, `updated_at` timestamp(0) NOT NULL DEFAULT &#x27;0000-00-00 00:00:00&#x27; COMMENT &#x27;修改时间&#x27;, `deleted_at` timestamp(0) NULL DEFAULT NULL COMMENT &#x27;删除时间&#x27;, PRIMARY KEY (`id`) USING BTREE) ;DROP TABLE IF EXISTS `t_user_log`;CREATE TABLE `t_user_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL COMMENT &#x27;t_user表id&#x27;, `type` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL COMMENT &#x27;更新类型，insert or update or delete&#x27;, `create_at` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP(0) COMMENT &#x27;创建时间&#x27;, PRIMARY KEY (`id`) USING BTREE) ; 四、INSERT 触发器在t_user表中建立insert触发器，当往t_user表中插入数据时，同时往t_user_log表插入一条数据。 可通过’new.列名’获取插入行的数据 123456DELIMITER $$CREATE TRIGGER tr_t_user_insert AFTER INSERT ON t_user FOR EACH ROWBEGIN insert into t_user_log(user_id, type) values(new.id, &#x27;insert&#x27;);END $$DELIMITER ; 插入数据 1INSERT INTO t_user(name, remark) VALUES(&#x27;name1&#x27;,&#x27;remark1&#x27;), (&#x27;name2&#x27;,&#x27;remark2&#x27;), (&#x27;name3&#x27;,&#x27;remark3&#x27;); 执行后在t_user_log表中会出现触发器插入的三条记录。 五、UPDATE 触发器在t_user表中建立update触发器，当更新t_user表中数据时，同时往t_user_log表插入一条数据。 可通过’new.列名’获取更新的新数据，通过’old.列名’获取更新前的老数据 12345678910DELIMITER $$CREATE TRIGGER tr_t_user_update AFTER UPDATE ON t_user FOR EACH ROWBEGIN IF new.updated_at &lt;&gt; old.updated_at THEN insert into t_user_log(user_id, type) values(new.id, &#x27;update&#x27;); ELSE insert into t_user_log(user_id, type) values(new.id, &#x27;manual update&#x27;); END IF;END $$DELIMITER ; 更新数据 123update t_user set remark=&#x27;remark11&#x27; where name=&#x27;name1&#x27;;update t_user set remark=&#x27;remark22&#x27;, updated_at=now() where name=&#x27;name2&#x27;; 执行后在t_user_log表中会出现触发器插入的2条记录。 六、DELETE 触发器在t_user表中建立delete触发器，当删除t_user表中数据时，同时往t_user_log表插入一条数据。 通过’old.列名’获取删除的数据 123456DELIMITER $$CREATE TRIGGER tr_t_user_delete AFTER DELETE ON t_user FOR EACH ROWBEGIN insert into t_user_log(user_id, type) values(old.id, &#x27;delete&#x27;);END $$DELIMITER ; 删除数据 1delete from t_user where name=&#x27;name1&#x27;; 执行后在t_user_log表中会出现触发器插入的1条记录。 七、后话本方法在《高性能MYSQL》一书的触发器一节有提及。虽然在开发过程中，已有的开发经验是应尽量避免甚至不使用触发器。但是在某些特定的场景，诸如本文描述的场景问题，使用触发器记录变更日志，加上触发器本身并不会改动业务逻辑，个人认为可以考虑临时使用触发器解决问题。当然,本文的场景，还有另外一种方法是，使用 canal + binlog 的方式同步数据。","categories":[],"tags":[]},{"title":"解决执行\"go build\"时报\"Host key verification failed.\"的错误","slug":"解决执行go build时报Host key verification failed的错误","date":"2021-10-20T03:52:31.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/10/20/解决执行go build时报Host key verification failed的错误/","link":"","permalink":"https://fenixadar.github.io/2021/10/20/%E8%A7%A3%E5%86%B3%E6%89%A7%E8%A1%8Cgo%20build%E6%97%B6%E6%8A%A5Host%20key%20verification%20failed%E7%9A%84%E9%94%99%E8%AF%AF/","excerpt":"","text":"解决执行”go build”时报”Host key verification failed.”的错误go版本 1.16+，项目存在引用私有库的情况，在执行”go build”时，总是报如下错误： 1234567go: xx.xxx.com/xxx/xxx@v0.1.0: reading xx.xxx.com/xxx/xxx/go.mod at revision v0.1.0: git ls-remote -q origin in /Users/xxx/go/pkg/mod/cache/vcs/xxxxx: exit status 128: Host key verification failed. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. google该错误，网上可以找到很多回答是说 known_host的指纹问题，但是单纯使用 ssh -T xx.xxx.com，并没有解决该问题。 通过 go build -x 可以看到 1/Users/xxx/go/pkg/mod/cache/vcs/xxxxx for git3 ssh://git@abc.xxx.com:8080/xxx/xxx.git 其实最后会到 abc.xxx.com:8080 拉取，所以我们应该解决的是添加 abc.xxx.com 的指纹 12345git clone ssh://git@abc.xxx.com:8080/xxx/xxx.gitCloning into &#x27;xxx&#x27;...The authenticity of host &#x27;[abc.xxx.com]:8080 ([10.1.1.100]:8080)&#x27; can&#x27;t be established.RSA key fingerprint is SHA256:xxxxx.Are you sure you want to continue connecting (yes/no/[fingerprint])? 回答 yes 后，known_host中就会出现 abc.xxx.com:8080 的指纹，再执行 go build 即可","categories":[],"tags":[]},{"title":"个人虚拟化集群搭建教程","slug":"个人虚拟化集群搭建教程","date":"2021-06-04T06:58:20.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/06/04/个人虚拟化集群搭建教程/","link":"","permalink":"https://fenixadar.github.io/2021/06/04/%E4%B8%AA%E4%BA%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、写在前面 本教程最重要还是在建设理念与思路，部分步骤中，因网上可轻松查到的资料，故会省略不详谈。 实际搭建过程中，几乎每个步骤均有多重选择，笔者会适当的描述这些选择项。 本文着重讲解利用家用组装机+pfsense软路由的方式搭建集群。 二、为什么要搭建个人虚拟化集群？做为一个开发，你是不是有以下几个痛点： MQ，mysql，redis等开发用软件越装越多，已经感觉到计算机明显变卡 开发环境软件本身以及其下载的文件诸如maven缓存等，占用大量磁盘空间，硬盘严重告急 开发软件所需配置也越来越多，已经记不清自己曾经配置过什么，甚至出现配置互相覆盖影响的问题 为了做技术架构探索选型，不得不在本地先安装许多软件，设置很多配置，完结后还得删掉以免影响系统运行速度，浪费诸多时间。 安装了vmware workstation，就为了能跑几个linux系统做实验，导致计算机内存告急，运行缓慢。 出差时，带性能好的笔记本太重，带轻薄的本子又太卡。更麻烦的是，你得在你每台计算机上重复配置一次，有时候还会遗漏配置项导致出错。 笔者也曾遇到过此类问题，并困扰了笔者很久。为了解决这个问题，我们可以提升单机的性能，但提升单机性能只能解决部分问题，并不能根本性的解决问题，诸如解决不了环境变量污染的问题。亦或者，我们也可以在云平台购买按量计费的云主机或者saas服务，此方法好处是能快速的得到你想要的机器，而且可供给的数量几乎是不限的，但缺点也很明显，如果你需要长期运行或者所需数量较多，该方法成本会变得相当高昂。 笔者最终解决该问题的方案是，搭建自己的虚拟化集群。 整体的网络拓扑结构很简单，如下图： 三、优势与劣势 优势： 虚拟化集群可以7x24小时不间断的提供你所需的环境。 多重选择，非常自由的配置，从网络到主机，从硬件到软件，基本上你可自主决定。 性价比较高，首次成本几千即可，后续成本基本是电费，根据你设备多少决定，低至大概30+元/月。 劣势： 需要暴露在公网环境下，必然会遭受各种网络攻击。 可靠性问题，因为只是个人搭建，在控制成本的前提下，可靠性稍弱，但因为个人使用，影响面不大。 需要你懂得一些的基础运维和网络的知识，诸如设备选型，设备安装，防火墙配置，网络环境架设，虚拟化软件的使用等一系列技能。 如果不想托管在专业机房或者单独隔离的房间，谨慎考虑购买企业级服务器，噪音跟飞机起飞一样，芜湖。。。没听过的朋友建议上B站感受一下。 与生产服务器集群的区别 本方案，基本没有考虑高可用，所以可靠性相比真正的生产集群会偏低。 投入费用较低，1台全新的Dell服务器的价格，少说也要几万元。而家用PC一台价格在6-7千之间的，性能就相当不错了。 家用组装机没有带外管理功能，发生故障时，可能需要到现场处理。 真正的服务器噪音比较大，而家用组装机噪音比较小。 生产服务器是需要放置到无尘且带有空调的机房的。 总之，可以这么理解，这个方案其实就是拿普通的机器当服务器使用。价格虽然低了，但维护成本高了，可靠性低了，只是因为个人使用，即使出现问题，影响的也只是自己而已，所以可靠性低一些可接受，个人搭建规模不会太大，维护成本总体可控。 四、关键性步骤 准备公网IP与域名 购买服务器、路由器、交换机等设备 安装并配置路由器、交换机等设备 安装ESXi与vCenter 在开始愉快的玩耍之前的准备工作 五、准备公网IP与域名5.1 局域网还是广域网？首先需要明确的是，你要搭建的虚拟化集群，是只想在局域网内使用，还是可以在广域网上连接？ 先说说只是在局域网内使用，建设难度会低一些，但同时，你也丧失了诸多特性。 如你把整个集群建设在公司局域网网内，离开了公司，你就连不上集群了，或者需要依赖于第三方的设备或者软件才能连的上。当然，很多公司特别是需要做二次验证的公司，未必会同意你自行接入私人的设备。亦或者，你把集群建设在家里，情况也类似，你在公司就连不上了。 总之，笔者不推荐只搭建在局域网内，本文也只针对于可在广域网上连接的方案进行介绍。 5.2 注册域名注册域名非常的简单，网上的教程也很多，可以在阿里云上注册一个域名并做好备案工作，本文不再赘述。 5.3 准备公网IP地址你需要能在广域网上连接到集群，那么你必定会需要一个公网的IP地址。 5.3.1 如何判断你是否拥有公网IP地址呢？ 通常在专业的机房，或者你能拉企业专线，那么你大概率会有固定的公网IP地址。 如果你是在家中搭建集群，利用的是家庭宽带，那么你大概率只能有动态的公网IP地址(可能需向宽带运营商申请)。 5.3.2 如何申请公网IP？ 如果你搭建在专业的机房，那么请联系机房管理员为你提供固定公网IP。 如果你是家庭宽带，那么你需要致电你的宽带运营商，申请获得一个公网IP，这通常需要几天时间，会有专人联系你，后续可能会有专业人员到你家中帮你配置光猫。笔者建议是，鉴于运营商提供的路由器相当一般，功能很少，而且安全性也不是很好，容易受到攻击。笔者建议自购路由器，运营商专业人员到家中时，你跟专业人员说会用自己的路由器拨号上网，专业服务人员会帮你把光猫配置好，你用自己的路由器拨号可上网即可。 如果能有固定的公网IP，是最好的选择。因为你向运营商申请的公网IP，它是动态的，更换的频率各地可能不一致，也许是一周，或者是一个月。这也意味着你需要定期更新域名所绑定的IP地址。因为偶尔会出现更新不及时的情况，特别跨省连接的时候，可能会有一小段时间(可能是几秒钟到几分钟)，会出现连接不上的情况。笔者测试过，最多发现会有15分钟的中断时间。 5.3.3 如何更新域名绑定IP地址？如果你已经有固定公网IP地址，你只需要在域名解析处一次性配置好你的IP地址即可，你可以跳过本小节。 举个例子，比如你的域名是托管在阿里云上的，你可以使用树莓派或者ESXi上的一台linux虚拟机，定时执行一个脚本，获取公网IP地址，而后利用阿里云SDK更新域名绑定的IP地址。 具体步骤如下： 所需软件安装与环境配置大致步骤如下：安装 python3，virtualenv，创建隔离的python运行环境 123456789yum install -y python3pip3 install virtualenvmkdir ~/ddnscd ~/ddns~/.local/bin/virtualenv venv source venv/bin/activatepip3 install requestspip3 install aliyun-python-sdk-alidns==2.6.29 编写Python脚本 请参考 https://help.aliyun.com/document_detail/29777.html 主要思路是获取域名当前的解析记录，和实时获取到的公网IP地址做对比，如果不一致，则更新域名的解析记录。 脚本如下，”xxx”处是需要你自行修改的部分： alidns.py123456789101112131415161718192021222324252627282930313233343536373839404142#!/usr/bin/env python#coding=utf-8from aliyunsdkcore.client import AcsClientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkalidns.request.v20150109.UpdateDomainRecordRequest import UpdateDomainRecordRequestfrom aliyunsdkalidns.request.v20150109.DescribeDomainRecordInfoRequest import DescribeDomainRecordInfoRequestimport requestsimport reimport timefrom time import strftime,gmtimeimport jsonclient = AcsClient(&#x27;xxx&#x27;, &#x27;xxx&#x27;, &#x27;xxx&#x27;)record_id = &quot;xxx&quot;request1 = DescribeDomainRecordInfoRequest()request1.set_accept_format(&#x27;json&#x27;)request1.set_RecordId(record_id)response1 = client.do_action_with_exception(request1)data_json = str(response1, encoding=&#x27;utf-8&#x27;)#print(data_json)ali_record_value = json.loads(data_json)[&#x27;Value&#x27;]print (strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, gmtime()), &quot;ali record value : &quot;, ali_record_value)html_text = requests.get(&quot;http://pv.sohu.com/cityjson?ie=utf-8&quot;).textip_text = re.search(u&quot;var returnCitySN = &#123;\\&quot;cip\\&quot;: \\&quot;(.*?)\\&quot;, \\&quot;cid.*\\&quot;&#125;;&quot;, html_text) new_public_ip = ip_text.group(1)if new_public_ip != ali_record_value : request2 = UpdateDomainRecordRequest() request2.set_accept_format(&#x27;json&#x27;) request2.set_RecordId(record_id) request2.set_RR(&quot;xxx&quot;) request2.set_Type(&quot;A&quot;) request2.set_Value(new_public_ip) response2 = client.do_action_with_exception(request2) print(strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, gmtime()), str(response2, encoding=&#x27;utf-8&#x27;)) print(strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, gmtime()), &quot;update complete, ali_record_value is &quot;, new_public_ip) 编写sh脚本 123cd ~/ddnssource ./venv/bin/activatepython3 alidns.py &gt;&gt; log.txt 添加定时任务定时任务配置为每5分钟运行一次12crontab -e*/5 * * * * sh ~/ddns/alidns.sh 六、购买设备6.1 概要搭建之初，你会需要购买一些的设备，大致有以下三大类： 网络设备，如路由器，交换机，网线 服务器机柜 计算机设备，如服务器，树莓派，NAS 6.2 网络设备6.2.1 路由器这里所说的路由器可不是家用的带wifi功能的路由器，而是企业级的路由器或者工控机。某宝或者某东上面都有售卖TPLINK，华为，H3C等企业级路由器。笔者的建议是，可以购买一台工控机，自行安装pfsense软路由系统，它既有路由的功能，也有防火墙的功能，安全上能有一定的保障。 要点: 不要购买普通的家用路由器，功能较少且难以保障稳定性与安全性。应该买带有线千兆网口的企业级路由器，如果买带耳朵能固定在机架上面的那就更好了 可以考虑买工控机，诸如倍控。自己安装软路由系统，诸如pfsense，iKuai，RouteOS等等。 性能上，根据自己需要的带机量而定，一般价格在大几百元到1千多的区间的即可。 6.2.2 交换机要点: 考虑到未来的拓展性，建议你买16口或者24口全千兆的二层交换机。 如果交换机可以上机架，那就更完美了。因为不论是16还是24口的交换机，必定会有很多条网线，不上机架的话，网线容易乱糟糟一团，不利于打理。 除非你的确有需要，否则不一定要买网管型的交换机。 6.3 服务器机柜如果你打算托管在机房，请跳过本小节。 不管搭建在家里，或是在公司，总会需要有个地方放置所有的设备，这时会需要一个机柜。某宝或者某东上面有很多机柜选择，而且基本都可送货到楼下。如果你不买机柜，网络、电源线必然会杂乱无章，很不好打理，各类设备所占的面积也大，所以还是购买一个机柜为佳。 6.4 计算机设备6.4.1 服务器的选择与购买服务器的选择非常的多样，你可以购买家用组装机当服务器使用，也可以购买真正的服务器。从大类来说，可以有以下三种方案可选择 选择家用组装机好处：价格低廉，简单粗暴，噪音小，适合家庭环境坏处：长时间运行可能会有可靠性的问题，没有故障指示灯等相关的设备，难以巡检，而且因为没有带外管理，出现故障无法远程处理。体积较大，浪费机柜空间 选择塔式服务器好处：一定的拓展性，各方面都比较中庸坏处：性价比比机架式服务器低，体积较大，浪费机柜空间。噪音虽然没用机架式那么大，但也不小。 选择机架式服务器好处：高性能，拓展性好，体积小，可以托管在IDC机房坏处：噪音大，不适合家庭环境 注意点：在你选择了一种方案后，后续最好延续使用该方案。特别的，如果你选择了家用组装机，CPU一开始买的是AMD，那么后续最好也都统一买AMD的CPU，否则会导致DRS、vSan都做不了。 关于真正的服务器，你可以买全新的，或者某宝上面也有很多二手的服务器。不过二手服务器虽然价格低，但可能会有坑，就看你敢不敢买了。 这里主要介绍下利用家用的组装机做虚拟化。网络上有很多教你购买和组装的教程，这里只说一些重点注意事项。 如何选择CPU？家用组装机的cpu，一般无非就是 Intel 和 AMD 两种，从性价比角度来看，目前的zen2、zen3架构如日中天，AMD性价比无疑比Intel更高。 如何选择主板？主板尽量不要购买小板，可以选择ATX，或者E-ATX的板型，因为板型小的主板，也意味着所提供的接口少，不利于将来扩展。另外，有个特别需要注意的点是，主板上的网卡芯片，一般有”Intel”和”Realtek瑞昱”两种，如果你买的是AMD的CPU，那么对应的一般价格的主板，大概率是Realtek芯片的板载网卡，而Realtek芯片的网卡，ESXi是识别不到的，这样一来你会需要额外购买Intel芯片的网卡。 如何选择内存？根据你买的CPU和主板类型不同，购买合适的内存即可。 如何选择硬盘？推荐购买 nvme协议 m.2接口 的ssd硬盘，因为速度真的很快。一般来说，计算机的瓶颈点会卡在IO上面。如果磁盘空间不够，可配合购买HDD硬盘，不需要联机的数据可以放NAS。 如何选择网卡？笔者的建议是无论你板载的网卡的芯片是Intel还是Realtek，你最好都额外购买一张pcie的有两个网口以上的Intel芯片的网卡。为什么要这么做呢？首先，利于远程配置(笔者有一次配置虚机网络的时，需要网卡先断线再连接到正确的虚拟网络，但在断开那张网卡后，远程就再也连不上了)，其次两个网卡利于增强可靠性，最后两个网卡才能让管理的流量和普通流量分开，彼此不会互相影响(迁移主机的时候，会有大量的管理流量产生，而如果你只有一张网卡，可能会影响到业务的正常通讯)。 如何选择显卡？如果你的cpu是不带核显的，那么会需要你额外购买一张显卡，建议买一张最低配的显卡即可，我们只是需要能显示而已。当然如果你有用GPU进行计算的需求，那么可根据实际需求选择显卡。 如何选择散热器？一般来说，风冷就足够使用了。如果cpu自带的风扇太弱，像Intel盒装cpu自带的小风扇就比较鸡肋，你可以自行购买风扇，价位在百元左右即可。至于是否上水冷，就看各位自己评估了，笔者的实践经验是如果搭载的不是发热量很大的CPU，又没有大量的计算需求，就不需要上水冷了。另外，请注意购买的风扇的接口是否兼容你买的cpu型号。 如何选择机箱？尽量买可以装三个HDD硬盘以上的机箱。尽量不要买小型的机箱，否则后续拓展麻烦且小机箱散热效果也不好。另外，如果你有服务器机柜的话，可以考虑买机架式的机箱，3U或者4U的，肯定比买普通机箱省空间，某宝上面很多。 如何选择电源？选择合适的电源即可，但要注意留一定冗余量，便于后续添加组件。选择电源未必非要追求金牌不可，功率合适，能稳定输出就好。 12345678910配置示例：AMD 锐龙7 3700X 处理器 7nm 8核16线程 3.6GHz 65W AM4接口 盒装CPU微星 MAG B550M BAZOOKA火箭炮电脑主板金士顿 FURY 32GB DDR4 2666 台式机内存条航嘉 WD500K 金牌500W电脑电源三星 1TB SSD固态硬盘 M.2接口(NVMe协议) 970 EVO微星 GT710 显卡酷冷至尊 暴雪T400 CPU散热器 支持I10 1200、AM4 /4热管/PWM温控先马 鲁班1 黑色 游戏电脑主机箱 该配置在21年6月价格总共在6k至7k左右。 6.4.2 树莓派树莓派是一种基于linux的单片机电脑，功耗较小，适合做一些简单的任务，价格在5百元左右。如果你的IP是动态公网IP，那么你可以考虑买一台树莓派，用于执行更新域名绑定IP的任务。当然你也可以不买树莓派，在虚拟机上创建一台linux主机来运行该任务，但有个问题是，假如承载该linux虚机的计算机发生宕机等的故障，很可能会导致更新任务无法执行，进而导致你连接失败。所以，从可靠性可用性的角度上看，把此任务单独放到树莓派上是有利于增强可靠性和可用性的。 6.4.3 NAS如果你有大量文件需要存储，那么买一台NAS无疑会更加保险。如果买的是支持万兆网卡的nas，后续可以升级做存算分离。 6.5 关于搭建的成本搭建的成本主要是第一次的购买设备的成本和平时的维护成本。第一次的购买设备的成本 = 路由器 + 交换机 + 服务器机柜 + 服务器x台数 + 树莓派 + NAS(含硬盘)集群搭建后，平时的成本主要是电费和维护费。举个例子，如果你按本文的家用配置搭建服务器，在不做大量密集计算的时候，功率大概在90w左右。机器24小时开机，一度电按照5毛来算，一天的一台服务器的电费成本大概是1块出头。维护费指的是，诸如硬件损坏，比如常见的硬盘长时间运行后损坏需更换的成本。 七、网络环境配置如果你买的是工控机想安装pfsense软路由系统，下载pfsense安装包时，记得Architecture选”AMD64 (64-bit)”，Installer选”USB Memstick Installer”，Console选”VGA”。使用pfsense的时候，我遇到过一个情况，当开机启动时VGA接口没有接入显示器，路由器工作不正常，这时候你只需要在启动路由器的时候接入显示器，等启动完成后再拔掉即可，或者你直接在某宝上面买个支持集显的VGA的伪装器。 除了pfsense之外，你也可以选择安装iKuai，RouterOS，OpenWrt等。 主要的步骤是 配置wan口，家庭线路主要是配置拨号上网账号密码，企业专线可能是配置一个固定的ip即可 配置端口转发策略 配置防火墙策略 八、安装ESXi与vCenter关于什么是 ESXi 与 vCenter ?https://docs.vmware.com/cn/VMware-vSphere/index.html 你需要在新装的电脑上安装 ESXi，安装后，将机器连接到交换机上。注意，你需要另一台pc机或者mac同时接到交换机上，这样你才能访问ESXi的web页面。具体怎么安装ESXi，网上已经有很多教程，我不再赘述。 是否一定要安装vCenter？答案是不一定要安装的，如果你有2台以上，或者单台机器但内存充足，但笔者建议安装。如果你只是简单使用，不需要经常创建虚机，那么不装vCenter也无妨。vCenter能提供的是更多的配置项，最重要的是能把虚机转成模板，这样你每次新建机器就不用重新做各种配置，而是从模板直接生成虚机，大大减少交付一台虚机的时间。 是否需要组DRS或者vSan？都不一定。组vSan的前提是3台以上的机器，且每台机器上都至少有1个SSD和3个HDD硬盘。到目前为止，我们所有的机器都是没有组raid的，硬盘损坏的时候会有丢失数据的风险，如果你对可靠性可用性和数据的安全性有一定的要求，那么你可以考虑组vSan集群，或者你可以利用nas+万兆网络做存算分离。 九、在开始愉快的玩耍之前前面的步骤做完后，我们已经基本上做完了整个环境的搭建，不过别着急，以下几点值得你注意一下 关于磁盘制备的选择在新建虚拟机的自定义硬件步骤，会有磁盘制备方式的选择，建议选择”精简制备”，默认的厚置备，会导致预先把划走你设置大小的磁盘空间。 制作主机模板你可以新创建虚拟机，安装linux系统，对系统进行安全加固等其他的初始化操作后，关机，并将主机转成模板。这样以后你新建虚拟机，就可以从模板部署了。 关于管理网络与普通网络如果你有两个甚至三个以上的网口，做好kernel端口与普通network端口的隔离与高可用的配置 设计IP地址的规划方案正常我们家用的时候，tplink路由器默认的网段规划是192.168.1.0/24，不过这时候我们会面临一个问题，当你虚机越来越多的时候，IP地址可能会不够用。所以，你应该提前规划好IP地址，掩码不再使用24，你可以使用10.0.0.0/20，这样一个网段内第一个可用IP是10.0.0.1，最后一个可用IP是10.0.15.254，一共有4094个可用IP了。你可以访问 https://www.w3cschool.cn/tools/index?name=ipcalc 来辅助计算规划IP地址。 谨慎使用端口转发你在内部搭建的各类系统，不要随意通过端口转发对外暴露，尤其是不要对0.0.0.0开放，系统难免有漏洞，容易被攻击，特别是在我们并没有专业安全防护解决方案的情况下。如果一定要对外暴露，可以考虑限制在一定的IP范围内。 十、写在最后到目前为止，你已经完成搭建工作了，接下来怎么用就看你的想象力了。以一个开发的视角来看，你可以搭建各类服务来辅助你的开发，比如搭建gitlab存储你的代码，搭建jenkins做CI/CD，部署mysql数据库，搭建nexus服务器加速jar包下载，搭建prometheus监控虚机状态。 HAVE FUN BE HAPPY!!!","categories":[],"tags":[]},{"title":"通过SSH隧道安全建立RDP远程桌面连接（RDP over SSH tunnel）","slug":"通过SSH隧道安全建立RDP远程桌面连接（RDP-over-SSH-tunnel）","date":"2021-05-07T16:18:52.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/05/07/通过SSH隧道安全建立RDP远程桌面连接（RDP-over-SSH-tunnel）/","link":"","permalink":"https://fenixadar.github.io/2021/05/07/%E9%80%9A%E8%BF%87SSH%E9%9A%A7%E9%81%93%E5%AE%89%E5%85%A8%E5%BB%BA%E7%AB%8BRDP%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E8%BF%9E%E6%8E%A5%EF%BC%88RDP-over-SSH-tunnel%EF%BC%89/","excerpt":"","text":"我有一台windows的虚拟机, 已经在路由器中对RDP的端口做了端口映射, 如此我便能在任何地方连接上这台虚拟机, 但问题也随之而来, 如何在保证易用的同时也适当的保障安全性？ 为什么要通过ssh隧道来建立远程桌面连接 RDP服务本身存在诸多风险, 不仅仅用户的弱口令问题, 还包括其本身也有诸多漏洞, 相比之下, 还是更相信SSH一些。 很多公司为了规避风险, 会在防火墙中限制3389端口的访问。但对SSH, 会宽容许多。当然, 即使安全策略没有彻底限制RDP, 这里也不建议在没有得到公司允许的情况下, 私自利用ssh隧道来建立RDP连接, 因为还是会存在诸多风险的。 思路通过SSH隧道安全建立RDP远程桌面连接的方法有许多种, 这里提供以下几种方法 方法1 win10通过配置可以打开 OpenSSH Server, 非win10可自行下载安装, 而后通过该Server建立ssh隧道, 本文重点介绍该方法 方法2 在内网中创建另外一个能和当前win主机互访的linux主机, 再建立隧道 方法3 如果你的路由是软路由系统并支持ssh tunnel, 可以直接利用软路由建立隧道 大致步骤: 在win10上打开 OpenSSH server 配置ssh server, 诸如改ssh端口, 启用密钥登录, 禁用密码登录 生成ssh key, 并将公钥拷贝到指定文件夹 将密钥拷贝到另一台计算机 在另一台计算机建立ssh隧道连接win10主机 具体步骤 打开”设置”-&gt;”应用和功能”-&gt;”可选功能”, 并安装”OpenSSH Server”功能 配置ssh server OpenSSH Server 的安装目录在”C:\\Windows\\System32\\OpenSSH”, 但我们需要在”C:\\ProgramData\\ssh”目录下, 修改”sshd_config”文件, 如果不能直接保存, 可先拷贝出来修改后再覆盖回去。 修改ssh默认端口, Port 22 改为 Port 55555 修改 PermitRootLogin 选项为 no, 即”PermitRootLogin no” 修改 PasswordAuthentication 选项为 no, 即”PasswordAuthentication no” 不注释该行 “PubkeyAuthentication yes” 不注释该行 “AuthorizedKeysFile .ssh/authorized_keys” 注释该行 “Match Group administrators” 注释该行 “AuthorizedKeysFile PROGRAMDATA/ssh/administrators_authorized_keys” 可参考”https://winaero.com/enable-openssh-server-windows-10/“ 生成ssh key, 并将公钥拷贝到指定文件夹 生成 ssh key 有很多种做法 很多程序员安装了”git extension” , 它自带了”putty key generator”可以生成key 利用OpenSSH本身的”ssh-keygen”生成, 可直接在”cmd”中键入”ssh-keygen”回车, 按照提示创建key, 最好为私钥创建一个密码。 默认”C://Users//用户名//.ssh//id_rsa.pub”文件便是公钥, 在该文件夹中创建”authorized_keys”, 并把公钥中的文本追加”authorized_keys”文件中。 将密钥拷贝到另一台计算机你一定会需要把你生成私钥拷贝到另外这台计算机上, 无论是windows还是linux, 一般都是放到用户文件夹下的”.ssh”文件夹。windows是类似”C://Users//用户名//.ssh”文件夹linux是类似”/home/用户名/.ssh”文件夹macos是类似”/Users/用户名/.ssh”文件夹 在另一台计算机建立ssh隧道连接win10主机 如果另一台计算机是 linux 或者 macos, 那么只需要打开”terminal”键入命令即可创建隧道, 命令类似 1ssh 用户名@公网IP或者域名 -p 33333 -L 12345:127.0.0.1:55555 -N -o ServerAliveInterval=60 -o ServerAliveCountMax=3 -f 用户名应填写win10的用户名 公网IP或者域名处应填写你的公网IP或者域名, 如果你是用路由器上网的, 应填写路由器的获取到的公网IP地址 33333是你路由器上暴露给外部的端口号 55555是路由器映射到win10的内部端口号 如果你是通过局域网内另外一台机器做隧道, 那么127.0.0.1应改为win10在内网中的IP地址 两个”-o”参数用来保证ssh隧道不会自动关闭 加 “-f” 参数, 可以让隧道在后台运行, 但同时也不方便我们关闭隧道, 若要关闭隧道, 可以先”lsof -i tcp:12345”获取PID值, 再通过”kill -9 PID值”来关闭隧道。我一般不加”-f”参数, 方便我随时关闭隧道。 “-N”参数表示只连接远程主机, 不打开远程shell 而后可以下载RDP客户端, windows自带远程桌面, linux可下载”xfreerdp”, macos可自行下载微软官方的远程桌面。新建RDP连接, ip地址填写”127.0.0.1”, 端口号写”12345”, 即可连接。 如果另一台计算机也是windows, 你可以像之前安装OpenSSH Server一样安装”OpenSSH Client”,或者安装开源免费的MobaXterm, 创建一个新Session, 按照下图设置即可。","categories":[],"tags":[]},{"title":"《深入浅出通信原理》一句话短评","slug":"《深入浅出通信原理》一句话短评","date":"2021-03-05T07:08:27.000Z","updated":"2022-08-04T10:46:42.844Z","comments":true,"path":"2021/03/05/《深入浅出通信原理》一句话短评/","link":"","permalink":"https://fenixadar.github.io/2021/03/05/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E3%80%8B%E4%B8%80%E5%8F%A5%E8%AF%9D%E7%9F%AD%E8%AF%84/","excerpt":"","text":"这本书其实是由某论坛系列连载的内容集结而成，总体来说，两个特点，一是简单易懂，简明扼要；二是需要一定的高等数学基础，公式略多。 读这本书我并没有想要完全理解这本书的所有内容，而是根据自己所需做了解知晓即可。这本书更多的是帮助我理解网络通信层面的一些东西，诸如物理层信号衰减等的原因。 这本书我只给评了6分，一方面是因为我并非通讯行业的行业人，而评估时加入了这本书对于自己的实用性指标。另一方面，出版这本书起因是因为连载，但如果真要深入浅出通讯原理，还是应该去看教材，毕竟过于简明扼要之后，会丢失诸多细节，也是因为如此，仅需做了解的我才会选择看这本书。 评分：6 （满分为10分） 1234567作者: 陈爱军出版社: 清华大学出版社出版年: 2018年2月第1版页数: 351定价: CNY 89.00装帧: 平装ISBN: 978-7-302-48386-1","categories":[],"tags":[]},{"title":"《持续交付2-0-业务引领的DevOps精要》-要点摘录与总结","slug":"《持续交付2-0-业务引领的DevOps精要》-要点摘录与总结","date":"2021-02-23T02:26:59.000Z","updated":"2022-08-04T10:46:42.836Z","comments":true,"path":"2021/02/23/《持续交付2-0-业务引领的DevOps精要》-要点摘录与总结/","link":"","permalink":"https://fenixadar.github.io/2021/02/23/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%982-0-%E4%B8%9A%E5%8A%A1%E5%BC%95%E9%A2%86%E7%9A%84DevOps%E7%B2%BE%E8%A6%81%E3%80%8B-%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95%E4%B8%8E%E6%80%BB%E7%BB%93/","excerpt":"","text":"一、概念篇为什么要持续交付？当前互联网变化非常迅速，在这个背景下，提升产品研发运营效率，快速发现新的机会并快速试错，降低试错成本已经变得非常重要。由此，带来几个问题： 如何平衡软件的质量与交付速度？ 如何让产品创新快速交付部署，并让团队得到反馈？ 我们都知道，要快速发现新机会并快速试错，就必须加快产品迭代速度，而加快迭代速度必然使得一些常规事务性占比增大，诸如测试成本，发布成本等。持续交互，即是这些问题的解决之道。 软件工程的发展历史让我们先搁置问题本身，先来回顾软件工程的发展历史。 瀑布软件开发模型1970年，Dr.Winston W.Rovce 首次提出瀑布软件开发模型，它将软件开发定义为多个阶段，每个阶段都有严格的输入和输出标准，很多人将这种开发方法称为“重型软件开发方法”。但这种方法会需在写第一行代码前，甲乙双方花费大量精力确定需求范围，编辑并审核软件需求说明书，即便如此，还是避免不了互相扯皮。 敏捷软件开发2001年，敏捷软件开发方法出现，敏捷方法强调发挥人的主观能动性，提倡面对面沟通，拥抱变化，通过迭代和增量开发尽早交付有价值的软件。和瀑布软件开发方法对比，敏捷能更快的看到可运行的软件，而不是到交付后期才能看到。此间，持续集成作为敏捷开发中的工程实践，率先被广泛的it组织所接受，它能减少大量重复性劳动，并排除某些沟通障碍。但敏捷方法并没有解决发布间隔长的问题，以及业务与研发团队关于需求变更和研发效率的矛盾。无论是瀑布或者敏捷开发，关注的都是如何快速将需求变为可交付的软件包。 DevOps2008年，DevOps萌芽，起初的想法是将敏捷实践应用于运维领域。DevOps概念本身也在不断的变化中，如下是曾经的定义 DevOps是一种软件工程文化和实践，旨在统一整合软件开发和软件运维。DevOps运动的主要特点是强烈倡导对构建软件的所有环节（从集成、测试、发布到部署和基础架构管理）进行全面的自动化和监控。 DevOps的目标是缩短开发周期，提高部署频率和更可靠地发布，与业务目标保持一致。 DevOps并非一个标准、一种模式或者一套固定方法，而是一种IT组织管理的发展趋势，也就是说，通过多种方式打破IT职能部门之间的隔阂，改变IT组织内部的原有合作模式，使之更紧密结合，从而促进业务迭代速度更快。这种发展趋势将会引起IT组织内部原有角色与分工的变化，甚至范围更大，会影响到相关的业务组织。对互联网公司来说，其软件产品对业务发展起到极其关键的作用，业务结果与IT效能强关联，因此顺应这一发展趋势的动力更加明显和迫切。 持续交付2010年，Jez Humble 和 Dave Farley 合著了《持续交付》一书，可以称之为“持续交付1.0”。持续交付1.0提供的原则和方法是DevOps运动的具体实操指引，事实上，敏捷开发更多的是涉及产品需求方，开发工程师，测试工程师。DevOps更多的是开发、测试和运维工程师。而持续交付1.0则涉及产品需求方，研发团队，运维团队。持续交付2.0是1.0的升级版，它将精益创业的最小化可行产品和持续交付1.0相结合，强调业务与IT间的快速闭环。 持续交付2.0核心概念与原则概念企业开发软件产品的目标是创造客户价值，为此，它必须不断探索发现真正要解决的业务问题，提出科学的目标，设计最小可行解决方案。通过快速实现解决方案并从真实反馈中收集数据，以验证该问题是否得以解决。这是一个从业务问题出发，到业务问题解决的完整业务闭环，简称为持续交付“8”字环。它由两个相连的环组成:第一个环为“探索环，其主要目标是识别和定义业务问题，并制订出最小可行解决方案进入第二个环；第二个环为“验证环”，其主要目标是以最快速度交付最小可行方案，可靠地收集真实反馈，并分析和验证业务问题的解决效果，以便决定下一步行动。 探索环包含4个可持续循环步骤，分别是提问、锚定、共创和精炼。 提问，即定义问题。通过有针对性的提问，找出客户的具体需求，并找出具体需求后的原因，即具体需求后要解决的根本问题。在提问中形成团队期望达成的业务目标或者想要解决的业务问题。如果问题无法清晰定义，那么找到的答案自然就会有偏差。因此，在寻找答案之前，应该先清晰地定义问题。 锚定，即定义结果目标指示器。针对问题进行信息收集，经过分析，去除干扰信息，识别问题假设，得到适当的衡量指标项，并用其描述现在的状况，同时讨论并定义我们接下来的行动所期望的结果。 共创，即共同探索和创造解决或验证该问题的多种具有可行性的解决方案。 精炼，即对所有的可行试验方案进行选择，找到最小可行性解决方案，它既可能是单个方案，也可能是多个方案的组合。 验证环也包含4个可持续循环的步骤，分别是构建、运行、监测和决策。 构建，是指根据非数字化描述，将最小可行性解决方案准确地转换成符合质量要求的软件包。 运行，是指将达到质量要求的软件包部署到生产环境或交到用户手中，并使之为用户提供服务。 监测，是指收集生产系统中产生的数据，对系统进行监控，确保其正常运行。同时将业务数据以适当的形式及时呈现出来。 决策，是指将收集到的数据信息与探索环得出的对应目标进行对比分析，做出决策，确定下一步的方向。 探索环就像是一部车子的前轮，把握前进方向。验证环则像车子的后轮，使车子平稳且驱动快速前进。它们之间相互促进，探索环产生的可行性方案规模越小，越能够提高验证环的运转速度；如果价值验证环能够提高运转速度，则有利于探索环尽早得到真实反馈，有利于快速决策，及时对前进方向进行验证或调整。 4个核心原则持续交付2.0可以使得企业以可持续发展的方式，在高质量、低成本及无风险的前提下，不断缩短持续交付“8”字环周期，从而与企业外部频繁互动，获得及时且真实的反馈，最终创造更多客户价值的能力。持续交付2.0有如下4个核心原则： 坚持少做在咨询的过程中，最常听到的一句话就是:我们最大的问题是人力不足。”无论公司实力如何，想做的事情永远超过自己的交付能力，需求永远做不完。然而，做得多就一定有效吗？我们应该抵住“通过大量计划来构建最佳功能”的诱惑，坚持少做，想办法对新创意尽早验证。 持续分解问题复杂的业务问题中一定会包含很多不确定因素，它们会影响问题解决的速度和质量。在实施解决方案之前，通过对问题的层层分解，可以让团队更了解业务，更早识别出风险。企业应该坚信，即便是很大的课题或者大范围的变更，也可以将其分解为一系列小变更，快速解决，并得到反馈，从而尽早消除风险。与其设计一大堆特性，再策划一个持续数月的一次性发布，不如持续不断地尝试新想法并各自独立发布给用户。 坚持快速反馈当把问题分解以后，如果我们仍旧只是一味地埋头苦干，而忽视对每项已完成工作的结果反馈，那么就失去了由问题分解带来的另一半收益，确认风险降低或解除。只有通过快速反馈，我们才能尽早了解所完成工作的质量和效果。 持续改进并衡量无论做了什么样的改进，如果无法以某种方式衡量它的结果，就无法证明真的得到了改进。在着手解决每个问题之前，我们都要找到适当的衡量方式，并将其与对应的功能需求放在同等重要的位置上，一起完成。 价值探索环意义探索环的目标是持续识别和定义三个有价值的假设： 用户假设，即我们提供的产品服务是针对某类潜在用户人群的需求的假设； 问题假设，即目标用户群之所以有这种需求，是因为他们的确存在某些痛点（或问题）需要解决的假设； 解决方案假设，即我们提供的解决方案可以解决这些痛点或问题，而且比其他现存的解决方案都有效且高效。 这3类假设中，任何一个假设不成立，都会导致我们事倍功半，甚至前尽弃。因此，我们需要选择并验证其中风险最高或最易验证的价值假设，并借助价值验证环得到数据反馈，以便深入理解用户需求，把握业务前进方向。 4个关键环节为了达成探索环的目标，我们需要经历4个关键环节： 提问该环节是持续交付“8”字环的起点。其目的在于通过不断地提问，澄清客户需求背后要实现的真正目标，以便找寻更多解决问题的方法，同时也有助于团队成员从业务问题出发，充分理解业务问题。 锚定“锚定”是设定目标以及目标分解的讨论过程，其目的是确定要达成的目标以及可以衡量它的指标，并能够指导后续的共创与精炼活动。对于目标的选择，应该遵循两点:一是识别价值指标，而非虚荣指标；二是指标应该可衡量且可获取，易于客观对比。 共创共创是指:当我们制订了想要达到的目标后，团队为设法验证或达成目标而找出多种可行性解决方案的过程。 共创分析方法有很多，书中列举了两个： 量化式影响地图它是用Why-who-how-What的分析法，通过结构化的显示方式，让团队寻找达成业务目标的方法。还应该了解当前的影响程度，以及对实施后达到效果的预期。也就是，从业务问题域出发，按“角色一影响一方案一量化”的顺序进行讨论，从而尽可能多地发掘出可行性解决方案。我们可以称它为“量化式影响地图”。我们有时无法马上对所有指标进行量化。此时可临时性地收集一部分数据，并进行相应的推断，通过一段时间的运行，进行指标量化的校准即可。另一种可能是希望衡量的指标较难直接量化。此时可通过一些过程指标或相近指标来替代。需要注意的是，这两种情况都存在一定的偏差，因此在数据的应用过程中，应该格外注意。 用户旅行地图用户旅行地图（user journey map）是指以可视化方式，将用户与产品或服务之间的互动，按业务流分阶段呈现出来。 在“共创”这一环节中，需要注意两个陷阱，分别是分析瘫痪（paralysis by analysis）和直觉决策（extinct by instinct）。分析瘫痪是指因为过度分析（或过度思考）而无法决策或采取行动，最终影响结果产出的一种状态。通常是由于有太多的细节选项，或者过于寻求最佳或“完美”的解决方案，并担心做出任何可能导致错误结果的决定。而直觉决策是指不做分析，基于匆忙的判断或直觉反应而做出致命的决定。它是与分析瘫痪相反的另一个极端。 精炼精炼环节就是对共创环节中得出的众多方案进行评估，从中筛选出团队认为最小可行性解决方案的过程。评估因素包括备选方案的实施成本、时间与人力、效果反馈周期，以及该方案对业务目标的影响程度。在VUCA环境中，时间是最大的隐形成本。精炼的目标并不是为了删除在共创阶段得出的解决方案，而是将它们按优先级排列，并让团队将解决方案进一步分解，顺序选出共同认可的最重要改进项，并确保它能够尽早被验证。 工作原则在探索环的工作中应该遵循“分解并快速试错”“一次只验证一点”“允许失败”原则。 分解并快速试错“一次到位式”解决方案通常需要较高的实施成本，而其带来的实际效果具有较高的不确定性。由于前期投入的成本较高（即沉没成本），一旦这个解决方案未能带来预期效果，团队不愿意放弃这一方案，决策者通常选择保留它，或者仍会持续优化，使其慢慢“死去”，而这会带来不必要的产品复杂度和维护成本。 一次只验证一点一次只验证一个需求假设。在执行整个试验方案过程中，我们仍旧要保持开放心态，不断优化这些试验方案。时刻提醒自己，我们的目标是验证我们的假设，试验方案只是我们验证假设的手段，而不是我们的目标。 允许失败尽管每个产品经理都希望所有方案都获得成功，但是我们却无法保证每个方案都会获得成功。但是，只要具有开放的心态，我们就可以从所有方案中都学到很多新的知识。 共创与精炼的常用方法关于共创与精炼，书中花了大量篇幅介绍了6个常用方法，这里我只简单介绍2个。 装饰窗方法所谓装饰窗方法（Decorative Window），就是指为新功能预留一个“入口”，让用户能够看到，但实际上并没有真正实现其功能。这是一种了解用户喜好的方法，其目的是利用最小成本，来验证用户是否喜欢某个功能，以及其紧迫程度，为是否研发后续更全面的解决方案提供数据支持。 最小可行特性法最小可行特性法（Minimum Viable Feature）是指在产品从1到n的过程中，寻找用户可直接感知到的需求假设作为产品的最小可行特性优先开发的方法，以尽可能少的成本快速增加或修改某个产品特性，让用户使用，收集真实反馈，专注于验证功能改进，同时也可提升用户使用体验。 快速验证环当我们通过“探索环”对最小可行方案达成共识以后，要借助“验证环”的快速运转，才能将其交付到用户（客户）手中，从而得到真实且可靠的反馈，以验证之。快速验证环的运转速度由两部分决定:一是探索环中得出的最小可行性解决方案的大小和复杂性；二是验证环自身运转的速度。 验证环的目标进入验证环的基本前提是“团队已达成共识，所选的方式是当前所处环境下，验证或解决业务领域问题的最佳方式“。验证环的目标就是借助各种方法与工具，让质量可靠的解决方案以最快的速度到达客户手中，从而收集并分析真实的反馈。 质量与速度是验证环的关键，它们却常常被认为是互斥的。然而， Puppet LabsDev发布的2017年DevOps现状调查报告结果显示，与低绩效IT组织相比，高绩效IT组织可以同时实现这两个目标，也就是说，发布质量好而且频率高。持续交付1.0在这方面发挥了巨大作用，如质量内建、小批量交付、自动化一切重复工作等。 验证环的4个关键环节验证环的主要工作内容就是以最可靠的质量和最快的速度，将最小可行性解决方案从描述性语言转换成可运行的软件包，并将其部署到生产环境中运行，准确收集相关数据并呈现，以便团队根据相关数据做出判断和决策。与探索环一样，它也包含4个环节，分别是构建、运行、监测和决策。 构建构建环节是将自然语言的描述转换成计算机可执行的软件，即“质量达标的软件包”。这一环节既要求相关人员能对业务问题及试验方案达成共识，又要求能够准确地将团队的意图转换成最终仅由0和1组成的数字程序。这一环节的参与角色最多，尤其当开发一个新产品或者产品有重大变更的时候，参与角色如业务人员、产品经理、开发工程师和测试工程师，以及运维工程师。每个角色的背景知识和技能优势各不相同，如何快速将人们头脑中的解决方案变成可以运行的高质量软件包，一直是软件工程领域的一个难题。这是验证环内不确定因素最多的一个环节。时间盒管理、工作任务分解和持续验证是应对这种不确定性的好方法。 运行将达到质量要求的软件包部署到生产环境或交到用户手中，并使之为用户提供服务。 监测监测环节收集数据，并统计展现结果、及时发现生产系统问题以及业务指标的异常波动，并做出适当的反应。它也是团队做出决策的最重要数据源之一。团队必须在验证环一开始就讨论并确定验证所需的数据需求，尽早讨论并定义数据需求规范制订日志记录标准，建立数据日志元数据，并与相对应的功能需求一并同时实现。 决策决策是指收到真实的业务数据反馈结果后，根据探索环中已确定的相应衡量指标进行对比分析，从而验证是否符合最初的预期。下一步行动既可能是从精炼环节的最小可行方案列表中选择下一个试验方案，也可能是返回到持续交付“8”字环的起点，开始新问题的探索。 工作原则验证环的工作原则主要包括质量内建、消除等待、尽量并行、监测一切。 二、组织机制组织机制是一个复杂课题，书中仅仅讨论持续交付所需的文化，以及建立文化的四步法。关于组织架构、人才结构、激励机制等内容被略去，不得不说是一个遗憾，当然我想更多的是篇幅所限，不得已而为之。 组织文化塑造四步法书中列举了几个企业组织的四步法，但大同小异，这里我以谷歌工程师的质量文化为例， 第一步:定义想要做的事情 提高代码质量，减少生产问题，减少手工测试工作量，快速发布软件。 第二步:定义期望的做事方法 开发团队编写自动化测试。 主动运行自动化测试用例。 做代码评审。 第三步:提供相应的培训 在公司范围内组织代码设计与自动化测试培训。 为每个团队指派自动化测试教练，帮助团队提高自动化测试技能。 第四步:做些必需的事情来强化那些行为 建立团队测试认证机制（test certified mechanism），共分3个大级别，12个子级，用于评估每个软件产品团队的测试成熟度。通过每个季度统计各级别上的团队数量分布，来评估自动化测试文化在公司内部的进展程度。 建立自动化测试组（ test group）和测试教练组（test mentor），帮助团队提升自动化测试能力。 建立代码评审资质证书。 代码合入版本仓库之前强制做代码评审。 代码评审之前，必须运行自动化测试用例，并提交报告给代码评审者。 当然，这4步并不是非常容易的，谷歌的执行过程也花费了4年的时间，其中还有很多非常具体的细节，书中并没有展开讨论。 行动原则行动原则有3个，分别是“价值导向，快速验证，持续学习”。 价值导向所有人都会一致同意，“我们做事情时，应该价值导向”。然而，这却是在工作中经常被忽视的一点，也是最难判断的一点。因为我们每天有太多的事情要做。为了能够早一点儿完成所有任务，我们常常忘记思考完成这些任务的最终目的，以及它与目标之间的关系。为了能够做出正确的判断我们应该时常强迫自己停下来，花一些时间，认真思考一下我们手头上正在做的事情是否仍旧具有价值，是否仍旧最有价值。之所以难以判断，是由于组织中每个人的背景与经历各不相同，对外部市场环境的感知也各不相同，对于同一个工作场所带来的价值感也会有所不同。因此，当我们讨论“价值”时，应该限定于一定的业务上下文，避免离题太远。同时，在讨论时应该尽量提供完整的上下文，并聆听他人的方案与建议。即便进行了充分的沟通与讨论，面对同一个问题的多种解决方案，我们可能也无法达成一致意见。此时，我们可以采用行动原则的第二原则，即“快速验证”。 快速验证在高度不确定的环境中，并不是所有的方案都能很容易提前对其价值进行准确判断因此我们需要快速验证。通过快速实施，得到真实反馈，从而做出决策。在一个安全的工作环境中，只要我们能够主动拥抱“快速验证”原则，充分发挥员工的主观能动性，就可以找到很多快速试验方案。对于与组织管理相关的改进，也可以使用快速验证方式。例如，针对具体问题，选择不同的试点团队进行快速实施，根据团队实际运行效果进行调优、验证。 持续学习我们无法保证每个决策都是正确的。团队应当将每一次反馈作为一次学习的机会，结合从中学习到的新知识，总结成功经验或失败教训。除了通过业务试验产生的业务结果对业务领域进行深入了解和学习，还要保持对做事过程的学习与反思，不断优化工作流程，提升各环节的效率。对于团队日常工作过程的学习与反思，有两种常见的方式，一是定期回顾，二是事件复盘机制。 关于持续学习，我认为是比较重要的，所以我重点介绍下持续学习。 定期回顾定期回顾是指每隔一定周期，团队主动安排一次会议，共同讨论在过去的这个周期内，团队在协作过程中的优点与不足，并讨论相应的对策，以便在后续的工作中能够保持优点，改进不足，持续取得进步。回顾会议结束后，应该有改进措施与计划，并能够跟踪执行结果。同时，不要制订过多的改进项，以免落入“反复提出，反复执行，没有实际进展”的境况。 复盘机制复盘机制通常是指针对发生的问题进行分析，其目的是避免相同问题重复出现。首先要针对问题发生的前后进行信息收集与整理确定问题的严重程度，理解问题发生的过程（对于疑难问题，可能还需要在事故后进行线下模拟测试，甚至线上测试，以复现问题和寻找原因）。然后进行根因分析，最后总结经验，制订改进措施与计划，并能够跟踪执行结果。对于根本原因分析，需要注意以下几点。 放松心态，开放共享。 分清“因”和“果”。 五问法，鼓励多问“为什么”。 发挥群体智慧。 不要停于表面，而要寻找深层次原因。 对答案进行求证。 对于每一次复盘，都应该详细记录和总结，作为知识在企业中全员共享。只有这样，才能收益最大化。 在以上两种学习方式中，都应该运用“系统思考”方法。简单来说，就是对事情全面思考，不能仅是就事论事，而是把想要获得的结果、实现该结果的过程、过程优化以及对未来的影响等一系列问题作为一个整体系统进行研究。在传统的思维模式中，人们假设因与果之间是线性作用的，即“因”产生“果”；但在系统思考中，因与果并不是绝对的，因与果之间有可能是环形互动的，即“因”产生“果”，此“果”又成为他“果”之“因”，甚至成为“因”之“因”。 度量原则作为管理者，如果无法度量，很显然你也无法有效率的进行改进。所以，我们也必须有度量原则。度量指标可以分为4类属性，分别是引领性指标、滞后性指标、可观测性指标和可行动性指标。 引领性指标与滞后性指标引领性指标是指那些对达成预定目标有着重要作用的指标。通常，一个好的引领性指标有以下两个基本特点:第一，它具有预见性；第二，团队成员可以影响这些指标。 滞后性指标是指那些为了达成最重要目标的跟踪性指标，如销售收入、利润率、市场份额、客户满意度等研究分析都属于滞后性指标。当你得到这些结果的时候，导致这些结果的事情早已结束，你得到的都是历史性结果数据。 例如，在其他因素相同的情况下，假如软件质量与性能越好，则软件的市场竞争力越强，客户就越愿意为之买单，软件销售量就会越高。对于软件销售这件事情，软件销售量就是一个滞后性指标，而软件质量与性能就是一个引领性指标。我们可以通过优化软件性能，提升软件质量来影响软件销售量，但无法确保一定达成软件销售量这一滞后性指标。企业的终极后验性指标是客户价值，相对于这一滞后性指标来说，其他指标均可认为是引领性指标。 可观测性指标与可行动性指标可观测性指标是指可以被客观监测到，但无法通过直接行动来改变的指标。可行动性指标是指在能力可触达范围内，通过团队努力可以设法直接改变的指标。 例如，千行代码缺陷率就是一种可观测性指标。我们无法以非常直接的方式来改变它，只能通过更全面的质量保障活动（写出高质量的代码、做更加完整的测试等活动）来影响这一指标。 代码规范符合度、代码圈复杂度、重复代码率则既是可观测性指标，也是可行动性指标，因为团队可以直接通过修改代码来直接影响和改变这些指标，但无法确保一定达成“千行代码缺陷率”这一后验性可观测性指标。 “DevOps状态报告2017”指出，衡量IT高绩效组织的4个度量项分别是发布频率、发布周期、MTBF/MTTR、吞吐量。其中，发布频率是指软件部署并运行于生产环境的频率，例如， Facebook手机App每周发布一次。该报告中的发布周期是指从代码提交到发布之间的时间周期。MTBF，全称是 Mean Time Between Failure，即平均失效间隔。就是新的产品在规定的工作环境条件下从开始工作到出现第一个故障的时间的平均值。MTTR的全称是 Mean Time To Repair，即平均恢复时间，指从故障出现到恢复之间的时间周期。吞吐量是指在给定时间段内系统完成的交付物数量。 假如将上述4个度量项作为滞后性指标的话，那么编译速度、测试时长、部署效率等指标则可能是达成这些目标的引领性指标。我们可以推断，从滞后性指标出发，一级一级地向前推导，可以发现很多可行动性的引领性指标。需要注意的是，指标之间的关联影响可能还存在时间延迟效应，即对某一个度量指标的改善，需要经过一段时间，才能在其关联度量指标上有所体现。并且，指标链条越长，可预测性就越低。 三、软件架构持续交付架构的要求为了提升交互速度，获得持续交付能力，我们会需要对系统架构做一些调整。书中对系统架构做了一些要求，要求如下： 为测试而设计（design for test）。如果我们每次写好代码以后，需要花费很大的精力，做很多的准备工作才能对它进行测试的话，那么从写好代码到完成质量验证就需要很长周期，当然无法快速发布。 为部署而设计（design for deployment）如果我们开发完新功能，当部署发布时，需要花费很长时间准备，甚至需要停机才能部署，当然就无法快速发布。 为监控而设计（design for monitor）。如果我们的功能上线以后，无法对其进行监控，出了问题只能通过用户反馈才发现。那么，持续交付的收益就会大幅降低了。 为扩展而设计（design for scale）。这里的扩展性指两个方面，一是支持团队成员规模的扩展；二是支持系统自身的扩展。 为失效而设计（design for failure）俗语说“常在河边走，哪能不湿鞋。”快速地部署发布总会遇到问题。因此，在开发软件功能之前，就应该考虑的一个问题是:一旦部署或发布失败，如何优雅且快速地处理。 系统拆分原则根据目前软件的发展趋势，以及持续交付的要求，对系统进行拆分有以下几个原则。 作为系统的一部分，每个组件或服务有清晰的业务职责，可以被独立修改，甚至被另一种实现方案所替代。 “高内聚、低耦合”，使整个系统易于维护，每个组件或服务只知道尽可能少的信息，完成相对独立的单一功能。 整个系统易于构建与测试。将系统拆分后这些组件仍需要组合在一起，为用户提供服务。 使团队成员之间的沟通协作更加顺畅。 常见架构模式微核架构微核架构（microcore architecture）又称为插件架构（plugin architecture），指的是软件的核心框架相对较小，而其主要业务功能和业务逻辑都通过插件实现，如图所示。核心框架部分通常只包含系统启动运行的基础功能，例如基础通信模块、基本渲染功能和界面整体框架等。插件则是互相独立的，插件之间的通信只通过核心框架进行，避免出现互相依赖的问题。 这种架构方式的优点有以下几个： 良好的功能延伸性（extensibility）:需要什么功能，开发一个插件即可。 易发布:插件可以独立地加载和卸载，使它比较容易发布。 易测试:功能之间是隔离的，可以对插件进行隔离测试。 可定制性高:适应不同的开发需要。 可以渐进式地开发:逐步增加功能。 当然，它也有不足，具体有以下几点: 扩展性（scalability）差，内核通常是一个独立单元，不容易做成分布式，但对客户端软件来说，这就不是一个严重问题。 开发难度相对较高，因为涉及插件与内核的通信以及内部的插件登记机制等，比较复杂。 高度依赖框架，既享受框架带来的方便性，当框架接口升级时又可能会影响所有插件，导致大量的改造工作。 微服务架构微服务架构（microservice architecture）是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于HTTP协议的 RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。这种软件架构的优点有以下几个。 扩展性好——各个服务之间低耦合。可以对其中的个别服务单独扩容，如图所示的D服务。 易部署——每个服务都是可部署单元。 易开发每个组件都可以进行单独开发，单独部署，不间断地升级。 易于单独测试——如果修改只涉及单一服务，那么只测试该服务即可。 但是，它也有不足，具体有以下几点。 由于强调互相独立和低耦合，服务可能会被拆分得很细。这导致系统依赖大量的微服务，变得很凌乱和笨重，网络通信消耗也会比较大。 一次外部请求会涉及内部多个服务之间的通信，使得问题的调试与诊断比较困难，需要更强大的工具支持。 为原子操作带来困难，例如需要事务类操作的场景。 跨服务的组合业务场景的测试比较困难，通常需要同时部署和启动多个微服务。公共类库的升级管理比较难。在使用有一些公共的工具性质的类库时，需要在构建每个微服务时都将其打包到部署包中。 在使用微服务架构模式时，除确保每个服务一定要能够独立部署之外，还要确保在部署升级时不影响其下游服务（例如通过支持API的多版本兼容方式），同时建立全面的微服务监测体系。 巨石应用巨石应用（monolithic application）也称巨石架构，是指由单一结构体组成的软件应用，其用户接口和数据访问代码都绑定在同一语言平台的同一应用程序。这种巨石架构应用通常表现为一个完整的包，如一个Jar包或者一个Node.js或 Rails的完整目录结构。只要有了这个包，就什么都有了。 组织良好的巨石架构同样也有其优势，包括以下几个。 利于开发和调试:当前所有开发工具和IDE都很好地支持了巨石应用程序的开发。系统架构简单，调试方便。 部署操作本身比较简单:例如，只需要有运行时所需部署的一个WAR文件（或目录层次结构）即可。 很容易扩展:只要在负载均衡器后面运行这个应用的多个副本就可以扩展应用程序。 它的劣势有以下几个。 对整体程序不熟悉的人来说，容易产生混乱的代码，污染整个应用，给老代码的学习和理解带来困难。 难与新技术共同使用。 只能将整个应用作为一个整体进行扩展。 持续部署非常困难。为了更新一个组件，必须重新部署整个应用程序。 架构改造实施模式通常，这类改造有3种实施模式，分别是拆迁者模式、绞杀者模式和修缮者模式。其中，绞杀者模式和修缮者模式都有利于持续交付，降低架构改造和发布的风险。 拆迁者模式“拆迁者模式”就是指根据当前的业务需求，对软件架构重新设计，并组织单独的团队，重新开发一个全新的版本，一次性完全替代原有的遗留系统，如图所示。 这种方式的好处在于，它与旧版本没有瓜葛，没有历史包袱，可以按预期进行架构设计。但是，这种模式的风险包括以下几个方面。 业务需求遗漏。软件的历史版本中，有很多不为人熟知的功能还在使用。 市场环境变化。由于新版本架构无法一蹴而就，当市场需求发生变化时，就会错失市场良机。 人力资源消耗大。必须分出人力，一边维护旧版本的功能或紧急需求，一边要安排充分人力进行架构改造。 “闭门造车”。新版本上线后，无法满足业务需求。 绞杀者模式“绞杀者模式”是指保持原来的遗留系统不变，当需要开发新的功能时，重新开发一个服务，实现新的功能。通过不断构建新的服务，逐步使遗留系统失效，并最终替代它，如图所示。 这种方式的好处在于: 不会遗漏原有需求； 可以稳定地提供价值，频繁地交付版本，可以让你更好地监控其改造进展； 避免“闭门造车”现象。 其劣势在于: 架构改造的时间跨度会变大； 产生一定的迭代成本。 修缮者模式“修缮者模式”是指将遗留系统的部分功能与其余部分隔离，以新的架构进行单独改善。 其收益包括: 系统外部无感知； 不会遗漏原有需求； 可以随时停下改造工作，响应高优先级的业务需求； 避免“闭门造车”现象。 而其劣势在于: 架构改造的时间跨度会变大； 会有更多额外的架构改造迭代成本。 数据库的拆分方法一般来说，关系型数据库很可能是巨石应用中的最大耦合点.因此，对于有状态微服务的改造，我们需要非常小心地处理数据库数据做数据库拆分时，我们应该遵循以下步骤，如图所示。 详细了解数据库结构，包括外键约束、共享的可变数据以及事务性边界等，如图a所示。 先拆分数据库，并按照12.3.2节的介绍进行数据迁移，如图b所示。 数据库双写无误后，找到程序架构中的缝隙，如图c所示。 将拆分出来的程序模块和数据库组合在一起，形成微服务，如图d所示。 四、基础设施前三个章节介绍了持续交付的概念，实施持续交付三大板块中的组织机制和软件架构，而最后一个板块则是基础设施。基础设施部分是产品研发过程中最基础的工作。 这部分涵盖持续交付部署流水线及其工具设计原则，以及建立该流水线和优化所需关注的五大领域，分别是，业务需求协作流程、分支与配置管理、构建与环境管理、自动化测试管理，以及部署发布与监控管理。这部分内容相当细节，我并不想在此展开。此外，此部分和目前流行的DevOps有大量共同的内容。 部署流水线为实现“谁构建，谁运营”，企业对于DevOps工具的建设，应该坚决从开发工程师的工作场景出发，为其构建强大的DevOps工具。不仅是生产环境的运维工具，而且是整个工作流程中的业务软件监控工程基础设施，它包括: 基础的研发流程自助平台，如各类运行环境（构建、测试、生产）的自助平台； 数据自助平台（包括三层监测数据）； 用于业务快速试错的实验测量平台； 针对移动设备，建立用户触达平台。 关于部署流水线，书中介绍了团队设计和使用部署流水线的原则，以及企业定制开发私有部署流水线工具链的设计要点和工具平台的能力要求。同时，还对四大基础支撑服务（编译构建服务、自动化测试服务、部署管理服务及基础环境服务）的逻辑组件进行了简要介绍。同时，还介绍了三大受信源（需求管理仓库、源代码仓库和制品库）之间的关联关系，以及对它们的管理要求。书中列举了几个不同的产品场景以及相应的部署流水线设计方案。 要想让部署流水线发挥最大的作用，研发团队需要尽可能遵守以下5条原则。 任何软件包的取用皆须通过受控源，各角色之间禁止通过私有渠道（如电子邮件、即时通信工具等）获取。 尽可能将一切流程自动化，并持续优化执行时间。 每次提交都能够自动触发部署流水线。 尽可能地少用手动触发方式。 必须执行立即暂停原则（stop the line） 业务需求协作管理业务需求协作管理一章具体阐述了产品版本周期准备期、交付期的重点内容，以及需求拆分带来的收益与随之而来的固定成本。如果无法降低这些固定成本，那么很难收获更大的价值。为了能够真正获得拆分带来的收益，在做需求拆分时就要尽可能遵守 INVEST原则（INV&lt;EST）为了帮助读者更好地掌握拆分技术。书中总结了五大拆分技法，以及每个用户故事应该包含的7个组成部分。需求分析与管理的方法与工具有很多，用户故事地图、用户故事树和依赖关系图是较为常见的需求梳理工具。另外，书中还介绍了迭代过程中提高团队协作的工具与方法，包括共享时间表、回顾会议、持续集成和故事验证。 分支与配置管理关于版本控制系统，如果不是有能力自定义自己代码仓库功能特性的大厂，个人强烈建议使用git，可以节省很多不必要的时间。如果还在使用svn等传统工具的团队，应尽快迁移到git中，git有提供非常方便的工具，方便svn用户做迁移，提交记录等信息都能比较好的迁移到git中。关于分支与配置管理，书中分析了各种分支策略的优点和挑战。目前的发展趋势是:软件发布频率越来越高，发布周期越来越短。硅谷顶级互联网公司多采用“主干开发”或高频的 GitHubFlow分支模式。一个企业到底选择哪种分支策略，需要根据团队的具体情况来决定。如果相关的配套条件（如软件架构、人员能力和工具平台的成熟度）不足，那么，盲目提高发布频率、缩短发布周期会造成不必要的损失。 “持续交付2.0”提倡鼓励持续集成的分支策略，因此，选择分支模式的原则有以下几条。 分支越少越好，最好只有一条主干。 分支生存周期越短越好，最好在3天以内。 在业务允许的前提下，发布周期越短越好。 持续集成本书还花了一章的篇幅讲述了持续集成的起源，团队实施持续集成的原则，介绍了持续集成6步提交法，以及快速建立团队持续集成实践的5个步骤。 需要注意的是，并不是安装部署了一个持续集成服务器，每天用它进行自动化编译打包，就说明团队正在使用持续集成实践。要真正做到持续集成，获得最大的持续集成收益，需要做到以下6点： 主干开发，频率提交代码。 每次提交都是完整有意义的工作。 提交构建阶段在10分钟之内完成。 提交构建失败后，立即修复；且其他人不得在修复之前提交代码。 应该在10分钟内修复失败，否则回滚引起失败的代码。 自动化构建成功后，团队对软件质量比较有信心。 自动化测试对交付频率的要求越高，希望前置周期越短，自动化测试就越为重要。书中阐述了软件快速交付对自动化测试的4项基本要求，即快速、便捷、可信和及时。为了能够做到这4点，需要以分层的自动化测试金字塔为指导合理设计自动化测试的实施策略，从而增加自动化测试的收益。对自动化测试的实践管理来说，有5条重要原则： 自动化测试用例运行次数越多，平均成本越低，收益就越大。 自动化测试用例之间应该尽可能相互独立，互不影响。 在质量有保障的前提下，自动化测试用例的数量越少越好。 遗留代码的自动化测试编写应该从代码热区开始。 自动化测试用例从测试金字塔的中间层开始补充，投入产出比最高。 软件配置管理良好的软件配置管理是打造持续交付部署流水线、加速持续验证环的基础支撑。本书讨论了软件配置管理的3个核心原则。 对一切进行版本管理。 共享唯一受信源。 标准化与自动化。 可以用下面5个问题来验证检查你是否对一切都做了版本管理。 产品源代码和测试代码是否放入了版本控制系统。 软件应用的配置信息是否放入了版本控制系统。 各类环境的系统配置是否放入了版本控制系统。 自动化的构建和部署脚本是否放入了版本控制系统。 软件包是否进行了版本管理。 另外，也可以用下面两个问题来检查软件配置管理是否做得足够好。 只要从源代码仓库中检出产品源代码仓库，就可以一键式自动化地构建出完整软件包吗？ 在没有他人的帮助下，任何团队成员都可以一键式自动化搭建出一套应用软件系统，用于体验产品新功能吗？ 低风险发布本节讨论了如何在快速部署发布的情况下通过多种技术手段降低风险，如开关技术、数据库迁移技术、蓝绿部署、金丝雀（灰度）发布、抽象分支以及暗部署等。并且强调，即便没有使用开关，假如团队能够一直使用“小步完整的代码提交”策略，也可以比较容易地做到将缺陷快速回滚。在一些业务场景下，我们的确无法直接高频地对外发布软件。但是，如果我们能够使用本章介绍的方法持续向预生产环境进行发布与部署，就可以尽早获得软件的相关质量反馈，从而减少正式发布后的风险。如果我们能够将每次发布的平均成本降低到足够低，那么将会直接改变团队的产品研发流程。 监测与决策生产环境的监测范围包括3个层次，它们分别是“基础监测”“应用监测”和“业务监测“。尽管根据每一层次的特点，监测数据的采集方式有所不同，但是其处理流程基本一致。每个监测体系都包括数据收集、上报、整理、分析、展现与决策这几个环节。而对监测系统能力的衡量有3个维度，即数据的准确性、全面性与及时性。而抽样能力是提高监测灵活性、节约资源、提升用户体验的一种有效方法。告警处理是研发人员和运维人员的常规工作但是，如果告警过多也会成为工作中的困扰，降低工作产出。因此，我们应该不断对告警点的设置与阈值计算方式进行优化，从而尽可能提升有效告警率。一旦告警成立，就需要启动问题处理流程。这个流程的最后两个环节“根因分析”和“根源解决”，是学习型组织的重要特征。随着发布频率的提高，测试场景的复杂性提高，越来越多的团队开始找寻方法在生产环境上进行软件测试，这被称为测试活动右移。这种右移目前多发生于展示性软件，这类软件出错后的成本和影响相对较少。而对那些交易性软件或回收成本较高的软件来说，测试左移的趋势也比较明显。右移的测试主要有两种类型。一是将测试用例在生产环境上自动运行。二是混沌工程，即通过注入“问题”，发现生产环境的潜在稳定性问题。 Netflix公司开发了一系列破坏性测试工具（Simian Army）可以促使工程师在软件设计与开发之时，就提前考虑各种失败的可能性，这被称为“为失败而设计（Design for Failure），从而提高生产环境的软件服务稳定性，为用户提供更好的服务体验。当收集到真实的数据反馈以后，我们就可以用来印证我们在价值探索环中所提出的假设或目标，并通过主动关联分析，最终确定是继续进行更多的试验，还是重新再选择一条新的“路”。 后续章节后续三个章节主要是实战案例的分析，分别代表不同类型的公司、不同大小的团队以及不同的软件产品特点。本书作者带领读者深入案例现场，了解当时状况，分析问题，并提出解决思路。由于是案例解析，此次不再摘录要点。","categories":[],"tags":[]},{"title":"《持续交付2.0 业务引领的DevOps精要》 一句话短评","slug":"《持续交付2-0-业务引领的DevOps精要》-一句话短评","date":"2021-02-23T01:19:24.000Z","updated":"2022-08-04T10:46:42.836Z","comments":true,"path":"2021/02/23/《持续交付2-0-业务引领的DevOps精要》-一句话短评/","link":"","permalink":"https://fenixadar.github.io/2021/02/23/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%982-0-%E4%B8%9A%E5%8A%A1%E5%BC%95%E9%A2%86%E7%9A%84DevOps%E7%B2%BE%E8%A6%81%E3%80%8B-%E4%B8%80%E5%8F%A5%E8%AF%9D%E7%9F%AD%E8%AF%84/","excerpt":"","text":"这本书带给鄙人诸多启发，DevOps，持续交付，都是近些年的热词，而本书作者分别从概念与原则，组织架构，软件架构，基础设施，案例剖析等几个方面很好的诠释了这两个热词，难得的是，这不仅仅只是概念，更有大量的具体操作方法和实践案例，很适合技术管理者和研发经理阅读。 评分：9 （满分为10分） 12345678910作者: 乔梁出版社: 人民邮电出版社出品方: 异步图书副标题: 业务引领的DevOps精要原作名: 持续交付2.0出版年: 2019年1月第1版页数: 327定价: 89.00元装帧: 平装ISBN: 978-7-115-50001-4","categories":[],"tags":[]},{"title":"写在开始本博客开始之前","slug":"写在开始本博客开始之前","date":"2021-01-21T03:38:58.000Z","updated":"2022-08-04T10:46:42.836Z","comments":true,"path":"2021/01/21/写在开始本博客开始之前/","link":"","permalink":"https://fenixadar.github.io/2021/01/21/%E5%86%99%E5%9C%A8%E5%BC%80%E5%A7%8B%E6%9C%AC%E5%8D%9A%E5%AE%A2%E5%BC%80%E5%A7%8B%E4%B9%8B%E5%89%8D/","excerpt":"","text":"本博客主要用于自己做总结沉淀。 本博客佛系经营，不刻意推广，不定期更新，一切随缘。 内容上，一是不追求全面完整，如只是教程，网上到处都是，无必要重写一遍。可能更多的是我提一些要点，放参考链接的形式。二是，想发一些自己曾经研究过，自己喜欢的知识和技能。","categories":[],"tags":[]},{"title":"2021新年寄语","slug":"2021新年寄语","date":"2021-01-19T09:43:28.000Z","updated":"2022-08-04T10:46:42.836Z","comments":true,"path":"2021/01/19/2021新年寄语/","link":"","permalink":"https://fenixadar.github.io/2021/01/19/2021%E6%96%B0%E5%B9%B4%E5%AF%84%E8%AF%AD/","excerpt":"","text":"过往的2020年真是令人终身难忘的大年，一场突如其来的疫情打乱了所有人的节奏，以前总觉得亲历历史是非常幸运的，现在回想自己还是太天真幼稚了，亲历历史更多带来的是苦难。辗转来到了2021年，终于，在2020年开个属于自己的博客的小愿望还是没能实现，虽然这已经是在2019年就计划了的，但总有诸多现实且世俗的因素使自己有借口原谅自己的拖沓。 如果只用单个词作为2020年的年度词，那就是虚拟化，这是2020年我的最大的收获，它直接为我打开了一扇大门，一扇能让我极度方便的实践各个技术路线的大门。在此之前，遇到的最大痛点就是环境问题，每次学习实验某个语言，某个平台，某个框架，我可能得在本地计算机安装相应的程序，或是做某些配置。于是，计算机里面充斥着各种语言平台，各种IDE，各种工具，各种环境变量，最后把机器搞成八国联军，甚至卡顿，环境变量冲突，给自己挖了不少坑。一直到我知道了vSphere之后，这一切就再也不是问题，我可以迅速的通过vCenter创建一个清洁的系统，安装部署自己所需要的环境。 搭建虚拟机集群服务器过程中，踩了不少坑，特别是探索最佳实践方式花了不少时间。该选哪种软路由系统比较合适，网络拓扑结构该如何设计，怎么配置acl、vlan等才既能保证一定的安全性，又保障易用性。期间又陆续出现各种原因导致的网络连接不稳定，简而言之，一个典型的三边工程，就这么磕磕绊绊边搞边验证了3个月，算是基本稳定下来了。 2020年也意识到自己需要加强对运维侧的理解。意识到这个点的原因是，在项目研发过程中，并没有考虑太多运维侧的东西，以至于在上线后，当出现一些莫名其妙的问题时，运维人员和开发人员都不能及时发现、分析、解决问题，运维忙于救火，开发维护成本过大。也是因为如此，今年花了不少时间整体性的了解devops，希望它能成为我保证项目质量的一颗银弹。 2021年，我想进一步了解并初步实践DevOps，如果可能的话，我希望再加上安全，也就是能实践基础版本的DevSecOps。我计划设计一个DevOps平台，并在实际的工作中加以实践。针对项目中会遇到的爆发性强，难预测，响应要求高，可用性要求高等特点，该DevOps平台应该包含项目管理，持续集成，自动部署，弹性伸缩，高可用，监控告警，微服务治理等功能，从需求、研发、构建、部署到最后的运维保障，全生命周期提供支撑和管理能力。该平台尽可能用开源项目搭建，截止目前，项目管理已采用禅道开源版，已稳定运行一段时间，容器使用docker，代码管理使用gitlab。CI/CD采用jenkins，但还在建设中。至于容器编排，制品管理，监控告警等其他模块，还未开始实质意义上的技术选型，但我想随着项目推进，研发人员到岗，我就能从各种杂事中脱身，肯定会逐渐加快脚步。如果进展顺利的话，我还想适当加入安全侧的模块，将安全左移，从代码审计，业务安全着手，再深入到蜜罐系统，WAF等等。 2021年，我也希望，我能真正的开写这个博客，可能未必很频繁的更新，但自己应该在忙碌中抽出一些时间做总结整理，真正沉淀些自己的东西。 预祝一切如愿。","categories":[],"tags":[]}],"categories":[],"tags":[]}